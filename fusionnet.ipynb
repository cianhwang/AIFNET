{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(path, number, train_type):\n",
    "    result=np.empty((number, 48, 48, 3), dtype=\"float64\")\n",
    "    for i in range(number):\n",
    "        I = cv2.imread(path + \"{:04}_{}.jpeg\".format(i+1, train_type))\n",
    "        I = I[8:-8, 8:-8, :]\n",
    "        result[i, :, :, :] = I\n",
    "    return result/result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = np.random.randint(0, 1, (10000, 48, 48, 3))\n",
    "# x_train1 = np.random.rand(10000, 48, 48, 3) * mask\n",
    "# x_train2 = np.random.rand(10000, 48, 48, 3) * (1-mask)\n",
    "\n",
    "# y_train = x_train1 + x_train2 + 0.25*np.random.rand(10000, 48, 48, 3)\n",
    "# y_train = y_train[:, 8:-8, 8:-8, :]\n",
    "dataNum = 1000\n",
    "\n",
    "x1 = load_imgs(\"./blurImg/\", dataNum, 1)\n",
    "x2 = load_imgs(\"./blurImg/\", dataNum, 2)\n",
    "y = load_imgs(\"./blurImg/\", dataNum, 0)\n",
    "y = y[:, 8:-8, 8:-8, :]\n",
    "x_train1, x_test1, x_train2, x_test2, y_train, y_test = train_test_split(\n",
    "    x1, x2, y, test_size=0.2)\n",
    "# mask_test = np.random.randint(0, 1, (2000, 48, 48, 3))\n",
    "# x_test1 = np.random.rand(2000, 48, 48, 3) * mask_test\n",
    "# x_test2 = np.random.rand(2000, 48, 48, 3) * (1-mask_test)\n",
    "\n",
    "# y_test = x_test1 + x_test2 + 0.25*np.random.rand(2000, 48, 48, 3)\n",
    "# y_test = y_test[:, 8:-8, 8:-8, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input size: Nonex48x48x3\n",
    "# output size: Nonex36x36x16\n",
    "def pre_convblock(x):\n",
    "    y = layers.Conv2D(filters = 64, kernel_size = (5, 5), padding = \"valid\", activation = \"relu\")(x)\n",
    "    y = layers.Conv2D(filters = 64, kernel_size = (5, 5), padding = \"valid\", activation = \"relu\")(y)\n",
    "    y = layers.Conv2D(filters = 16, kernel_size = (5, 5), padding = \"valid\", activation = \"relu\")(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor format: [batch, in_height, in_width, in_channels]\n",
    "# input size: Nonex36x36x32 (cat: 16+16)\n",
    "# output size: Nonex32x32x2\n",
    "# softmax is applied along the channel axis.\n",
    "def post_convblock(x):\n",
    "    y = layers.Conv2D(filters = 64, kernel_size=(3, 3), padding = \"valid\", activation = \"relu\")(x)\n",
    "    y = layers.Conv2D(filters = 32, kernel_size=(1, 1), padding = \"valid\", activation = \"relu\")(y)\n",
    "    y = layers.Conv2D(filters = 2, kernel_size=(3, 3), padding = \"valid\", activation = 'tanh')(y)\n",
    "#    y = layers.Conv2D(filters = 2, kernel_size=(3, 3), padding = \"valid\")(y)\n",
    "    y = layers.Softmax(axis = -1)(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: out-of-focus image block A & block B, which denote the same area of the whole picture.\n",
    "#        each: 48x48x3\n",
    "# output: \n",
    "def fusionnet(inTensor1, inTensor2):\n",
    "    out1 = pre_convblock(inTensor1)\n",
    "    out2 = pre_convblock(inTensor2)\n",
    "\n",
    "    x = layers.Concatenate(axis = -1)([out1, out2])\n",
    "    y = post_convblock(x)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionnetPos(y):\n",
    "    y, inTensor1, inTensor2 = y\n",
    "## crop the input images to the same size as network output.\n",
    "    inCrop1 = layers.Cropping2D(cropping=((8, 8), (8, 8)))(inTensor1)\n",
    "    inCrop2 = layers.Cropping2D(cropping=((8, 8), (8, 8)))(inTensor2)\n",
    "    #y1, y2 = tf.split(y, [1, 1], axis = 3)\n",
    "    ## extend y1&y2 dimension to 3, consistant to color channels\n",
    "    y1 = y[:, :, :, :1]\n",
    "    y2 = y[:, :, :, 1:]\n",
    "#     print(y1.shape)\n",
    "#     print(y2.shape)\n",
    "    y1 = K.tile(y1, [1, 1, 1, 3])\n",
    "    y2 = K.tile(y2, [1, 1, 1, 3])\n",
    "    y1 = layers.Multiply()([inCrop1, y1])\n",
    "    y2 = layers.Multiply()([inCrop2, y2])\n",
    "    y = layers.Add()([y1, y2])\n",
    "#    print(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = layers.Input(shape=(48, 48, 3))\n",
    "img2 = layers.Input(shape=(48, 48, 3))\n",
    "intermed = fusionnet(img1, img2)\n",
    "# print(intermed)\n",
    "pred = layers.Lambda(fusionnetPos)([intermed, img1, img2])\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 48, 48, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 48, 48, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 44, 44, 64)   4864        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 44, 44, 64)   4864        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 40, 40, 64)   102464      conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 40, 40, 64)   102464      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 36, 36, 16)   25616       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 36, 36, 16)   25616       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 36, 36, 32)   0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 34, 34, 64)   18496       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 34, 34, 32)   2080        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 2)    578         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, 32, 32, 2)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 32, 32, 3)    0           softmax_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 287,042\n",
      "Trainable params: 287,042\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = Model(inputs = [img1, img2], outputs = pred)\n",
    "generator.summary()\n",
    "generator.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generator.fit([x_train1, x_train2], y_train, epochs=10, batch_size=64)\n",
    "\n",
    "# prediction = generator.predict([x_test1, x_test2])\n",
    "# # print(np.sum(np.square(y_test-prediction)))\n",
    "# # print(np.sum(np.square(y_test-x_test1[:, 8:-8, 8:-8, :]-x_test2[:, 8:-8, 8:-8, :])))\n",
    "\n",
    "# # get image of generated mask\n",
    "# get_layer_output = K.function([generator.layers[0].input, generator.layers[1].input],\n",
    "#                                   [generator.layers[-2].output])\n",
    "\n",
    "# layer_output = np.array(get_layer_output([x_test1, x_test2])[0])\n",
    "\n",
    "# img_idx = 100\n",
    "# fig=plt.figure(figsize=(12, 12))\n",
    "# columns = 5\n",
    "# rows = 1\n",
    "# fig.add_subplot(rows, columns, 1)\n",
    "# plt.imshow(x_test1[img_idx, 8:-8, 8:-8, :])\n",
    "# fig.add_subplot(rows, columns, 2)\n",
    "# plt.imshow(x_test2[img_idx, 8:-8, 8:-8, :])\n",
    "# fig.add_subplot(rows, columns, 3)\n",
    "# plt.imshow(layer_output[img_idx, :, :, 0])\n",
    "# fig.add_subplot(rows, columns, 4)\n",
    "# plt.imshow(prediction[img_idx, :, :, :])\n",
    "# fig.add_subplot(rows, columns, 5)\n",
    "# plt.imshow(y_test[img_idx, :, :, :])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### ERROR REASON: activation function should have ()\n",
    "\n",
    "# discriminator = Sequential()\n",
    "# discriminator.add(layers.Conv2D(filters = 32, \n",
    "#                                 kernel_size = (5, 5), \n",
    "#                                 strides = (2, 2), \n",
    "#                                 padding='same', activation = layers.LeakyReLU, input_shape=(32,32,3)))\n",
    "# discriminator.add(layers.Conv2D(filters = 64, kernel_size = (5, 5), strides = (1, 1),\n",
    "#                                padding='same', activation = layers.LeakyReLU))\n",
    "# discriminator.add(layers.Conv2D(filters = 64, kernel_size = (5, 5), strides = (2, 2),\n",
    "#                                padding='same', activation = layers.LeakyReLU))\n",
    "# discriminator.add(layers.Conv2D(filters = 128, kernel_size = (5, 5), strides = (1, 1),\n",
    "#                                padding='same', activation = layers.LeakyReLU))\n",
    "# discriminator.add(layers.Conv2D(filters = 128, kernel_size = (5, 5), strides = (4, 4),\n",
    "#                                padding='same', activation = layers.LeakyReLU))\n",
    "# discriminator.add(layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (1, 1),\n",
    "#                                padding='same', activation = layers.LeakyReLU))\n",
    "# discriminator.add(layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (4, 4),\n",
    "#                                padding='same', activation = layers.LeakyReLU))\n",
    "# discriminator.add(layers.Flatten())\n",
    "# discriminator.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disnet(x):\n",
    "    y = layers.Conv2D(filters = 32, kernel_size = (5, 5), strides = (2, 2), \n",
    "                      padding='same')(x)\n",
    "    y = layers.LeakyReLU()(y)\n",
    "    y = layers.Conv2D(filters = 64, kernel_size = (5, 5), strides = (2, 2),\n",
    "                      padding='same')(y)\n",
    "    y = layers.LeakyReLU()(y)\n",
    "    y = layers.Conv2D(filters = 64, kernel_size = (5, 5), strides = (2, 2),\n",
    "                      padding='same')(y)\n",
    "    y = layers.LeakyReLU()(y)\n",
    "    y = layers.Conv2D(filters = 128, kernel_size = (5, 5), strides = (2, 2),\n",
    "                      padding='same')(y)\n",
    "    y = layers.LeakyReLU()(y)\n",
    "    y = layers.Conv2D(filters = 128, kernel_size = (5, 5), strides = (2, 2),\n",
    "                      padding='same')(y)\n",
    "    y = layers.LeakyReLU()(y)\n",
    "#     y = layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (1, 1),\n",
    "#                                padding='same', activation = layers.LeakyReLU())(y)\n",
    "#     y = layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (4, 4),\n",
    "#                                padding='same', activation = layers.LeakyReLU())(y)\n",
    "    y = layers.Flatten()(y)\n",
    "    y = layers.Dense(1, activation='sigmoid')(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 4, 64)          102464    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2, 2, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1, 1, 128)         409728    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 770,945\n",
      "Trainable params: 770,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dis_input = layers.Input(shape=(32, 32, 3))\n",
    "dis_output = disnet(dis_input)\n",
    "discriminator = Model(inputs = dis_input, outputs = dis_output)\n",
    "# make_trainable(discriminator, False)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gannet(x):\n",
    "    img1, img2 = x\n",
    "    pred = generator([img1, img2])\n",
    "    prob = discriminator(pred)\n",
    "    discriminator.trainable = False\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 48, 48, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 48, 48, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 32, 32, 3)    287042      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 1)            770945      model_1[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,057,987\n",
      "Trainable params: 287,042\n",
      "Non-trainable params: 770,945\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prob = gannet([img1, img2])\n",
    "gan = Model(inputs = [img1, img2], outputs= prob)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator.trainable = False\n",
    "# gan.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# gan.summary()\n",
    "# discriminator.trainable = True\n",
    "# discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.7018 - acc: 0.3438\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.6956 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.6939 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.7115 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.6915 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.7543 - acc: 0.0625\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 0.6901 - acc: 0.5312\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.8668 - acc: 0.0625\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.7099 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.6211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.6942 - acc: 0.5312\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.7263 - acc: 0.0625\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6917 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.6652 - acc: 0.6875\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.7054 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.6947 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.6959 - acc: 0.5625\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6963 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.7158 - acc: 0.4062\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6901 - acc: 0.4219\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.7281 - acc: 0.5938\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6957 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.6864 - acc: 0.6875\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6994 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.7399 - acc: 0.1875\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6768 - acc: 0.5312\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.7370 - acc: 0.7188\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 0.7272 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 0.7228 - acc: 0.3438\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.6937 - acc: 0.5469\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 0.7331 - acc: 0.0938\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 24ms/step - loss: 0.6956 - acc: 0.4375\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.6827 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 25ms/step - loss: 0.6940 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 0.6962 - acc: 0.2500\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 26ms/step - loss: 0.6938 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.6986 - acc: 0.1562\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 28ms/step - loss: 0.6945 - acc: 0.4375\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 0.6920 - acc: 0.6562\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 29ms/step - loss: 0.6964 - acc: 0.4062\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s 64ms/step - loss: 0.7035 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 31ms/step - loss: 0.6941 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s 67ms/step - loss: 0.6858 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 32ms/step - loss: 0.6971 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s 71ms/step - loss: 0.6709 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.6949 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s 72ms/step - loss: 0.6773 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.7079 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.6603 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.7000 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.6545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.6948 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.6883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6940 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.6870 - acc: 0.9688\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.6812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.6896 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.5918 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 0.7036 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.6916 - acc: 0.7500\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 0.6928 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 3s 94ms/step - loss: 0.6707 - acc: 0.9062\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 45ms/step - loss: 0.6863 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 3s 98ms/step - loss: 0.5870 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 46ms/step - loss: 0.6995 - acc: 0.5469\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.7000 - acc: 0.0312\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 49ms/step - loss: 0.6915 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.6662 - acc: 0.8125\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 50ms/step - loss: 0.6945 - acc: 0.4062\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 3s 105ms/step - loss: 0.7120 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 51ms/step - loss: 0.6865 - acc: 0.6094\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 3s 107ms/step - loss: 0.6386 - acc: 0.7812\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 52ms/step - loss: 0.6980 - acc: 0.5312\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 0.7291 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 54ms/step - loss: 0.6948 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.7046 - acc: 0.0938\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 4s 55ms/step - loss: 0.6862 - acc: 0.5625\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.5107 - acc: 0.9062\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.6992 - acc: 0.5469\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 0.7164 - acc: 0.0312\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 0.6940 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 4s 124ms/step - loss: 0.6713 - acc: 0.8438\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 0.6957 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 4s 127ms/step - loss: 0.6991 - acc: 0.3438\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 4s 61ms/step - loss: 0.6965 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 4s 127ms/step - loss: 0.6807 - acc: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "64/64 [==============================] - 4s 65ms/step - loss: 0.6947 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 4s 134ms/step - loss: 0.7077 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.6901 - acc: 0.5938\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 0.6007 - acc: 0.9375\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 4s 67ms/step - loss: 0.6880 - acc: 0.5781\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 0.7209 - acc: 0.0625\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 4s 68ms/step - loss: 0.6875 - acc: 0.5312\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 0.7125 - acc: 0.1875\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 4s 69ms/step - loss: 0.7016 - acc: 0.5625\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 0.7203 - acc: 0.1250\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 5s 71ms/step - loss: 0.6844 - acc: 0.5625\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.4517 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 5s 72ms/step - loss: 0.7485 - acc: 0.3906\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.7377 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 5s 74ms/step - loss: 0.6912 - acc: 0.5625\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.6894 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 5s 75ms/step - loss: 0.6849 - acc: 0.5469\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.6664 - acc: 0.6562\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 5s 78ms/step - loss: 0.6847 - acc: 0.5312\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 5s 168ms/step - loss: 0.7651 - acc: 0.0625\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 5s 81ms/step - loss: 0.6968 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 5s 170ms/step - loss: 0.7564 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 5s 83ms/step - loss: 0.7015 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 5s 170ms/step - loss: 0.7008 - acc: 0.3438\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 5s 82ms/step - loss: 0.7187 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 5s 170ms/step - loss: 0.6652 - acc: 0.8125\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 5s 84ms/step - loss: 0.6978 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 6s 178ms/step - loss: 0.7089 - acc: 0.2188\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 5s 85ms/step - loss: 0.6906 - acc: 0.5625\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 6s 177ms/step - loss: 0.7373 - acc: 0.2188\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 6s 88ms/step - loss: 0.6624 - acc: 0.5625\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 0.3725 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 6s 89ms/step - loss: 0.8038 - acc: 0.6094\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.7731 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 6s 91ms/step - loss: 0.6870 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.5800 - acc: 0.8438\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 6s 91ms/step - loss: 0.7116 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 0.7620 - acc: 0.0312\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 0.7008 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 0.7718 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.6935 - acc: 0.5625\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.7259 - acc: 0.1562\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 6s 96ms/step - loss: 0.6895 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.6821 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.7455 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 7s 206ms/step - loss: 0.6409 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 7s 102ms/step - loss: 0.7181 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 7s 207ms/step - loss: 0.6449 - acc: 0.9375\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 7s 102ms/step - loss: 0.6955 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 7s 212ms/step - loss: 0.7332 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 7s 102ms/step - loss: 0.6969 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 7s 213ms/step - loss: 0.6994 - acc: 0.3750\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 7s 105ms/step - loss: 0.7003 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 7s 218ms/step - loss: 0.6925 - acc: 0.5625\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 7s 108ms/step - loss: 0.6978 - acc: 0.4219\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 0.7205 - acc: 0.0938\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 7s 109ms/step - loss: 0.6939 - acc: 0.4375\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 0.7093 - acc: 0.2188\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 7s 113ms/step - loss: 0.6930 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 0.7297 - acc: 0.0625\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 7s 116ms/step - loss: 0.6964 - acc: 0.5312\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 7s 230ms/step - loss: 0.7074 - acc: 0.2812\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 7s 116ms/step - loss: 0.6916 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 8s 234ms/step - loss: 0.6742 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 7s 114ms/step - loss: 0.6969 - acc: 0.5625\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 8s 235ms/step - loss: 0.7581 - acc: 0.0312\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 7s 117ms/step - loss: 0.6967 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 0.7101 - acc: 0.1250\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 8s 118ms/step - loss: 0.6955 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 0.7284 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 8s 120ms/step - loss: 0.7009 - acc: 0.5469\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 8s 248ms/step - loss: 0.7352 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 8s 121ms/step - loss: 0.6926 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 8s 253ms/step - loss: 0.6833 - acc: 0.5938\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 8s 124ms/step - loss: 0.6888 - acc: 0.6250\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 8s 255ms/step - loss: 0.6692 - acc: 0.6250\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 8s 126ms/step - loss: 0.6949 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 8s 259ms/step - loss: 0.7206 - acc: 0.2188\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 8s 127ms/step - loss: 0.6948 - acc: 0.4375\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 8s 264ms/step - loss: 0.7315 - acc: 0.1562\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 8s 129ms/step - loss: 0.6880 - acc: 0.5625\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.7230 - acc: 0.2812\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 8s 131ms/step - loss: 0.6968 - acc: 0.5312\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 9s 268ms/step - loss: 0.8197 - acc: 0.0312\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 9s 133ms/step - loss: 0.6946 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 9s 272ms/step - loss: 0.7182 - acc: 0.3125\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 9s 137ms/step - loss: 0.7256 - acc: 0.4531\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 9s 285ms/step - loss: 0.7484 - acc: 0.1250\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 9s 142ms/step - loss: 0.7117 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 9s 283ms/step - loss: 0.7382 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 9s 145ms/step - loss: 0.6951 - acc: 0.5312\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 9s 293ms/step - loss: 0.7123 - acc: 0.1250\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 9s 141ms/step - loss: 0.6927 - acc: 0.5625\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 9s 297ms/step - loss: 0.6350 - acc: 0.7188\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 9s 142ms/step - loss: 0.7802 - acc: 0.5312\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 9s 295ms/step - loss: 0.6521 - acc: 0.7188\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 10s 151ms/step - loss: 0.6923 - acc: 0.5312\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 10s 307ms/step - loss: 0.7384 - acc: 0.0938\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 10s 151ms/step - loss: 0.7005 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 10s 300ms/step - loss: 0.6929 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 10s 149ms/step - loss: 0.6949 - acc: 0.4375\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 10s 307ms/step - loss: 0.7495 - acc: 0.0625\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-cab2079fff81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#discriminator.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1263\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "batchSize = 32\n",
    "losses = {\"d\":[], \"g\":[]}\n",
    "for e in range(epoch):\n",
    "    rand_idx = np.random.randint(0, x_train1.shape[0], size = batchSize)\n",
    "    img_batch1 = x_train1[rand_idx, :, :, :]\n",
    "    img_batch2 = x_train2[rand_idx, :, :, :]\n",
    "    y_batch = y_train[np.random.randint(0, y_train.shape[0], size = batchSize), :, :, :]\n",
    "    img_fake = generator.predict([img_batch1, img_batch2])\n",
    "    img_valid = y_batch\n",
    "    dis_input = np.concatenate((img_fake, img_valid), axis = 0)\n",
    "    label = np.append(np.zeros((batchSize, )), np.ones((batchSize, )))\n",
    "    #make_trainable(discriminator, True)\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #discriminator.summary()\n",
    "    d_loss = discriminator.train_on_batch(dis_input, label)\n",
    "    losses[\"d\"].append(d_loss)\n",
    "    \n",
    "    \n",
    "    gan_label = np.ones((batchSize,))\n",
    "    discriminator.trainable = False\n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #gan.summary()\n",
    "    g_loss = gan.train_on_batch([img_batch1, img_batch2], gan_label)\n",
    "    losses[\"g\"].append(g_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = generator.predict([x_train1, x_train2])\n",
    "# print(np.sum(np.square(y_test-prediction)))\n",
    "# print(np.sum(np.square(y_test-x_test1[:, 8:-8, 8:-8, :]-x_test2[:, 8:-8, 8:-8, :])))\n",
    "\n",
    "# get image of generated mask\n",
    "get_layer_output = K.function([generator.layers[0].input, generator.layers[1].input],\n",
    "                                  [generator.layers[-2].output])\n",
    "\n",
    "layer_output = np.array(get_layer_output([x_train1, x_train2])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_idx = 345\n",
    "fig=plt.figure(figsize=(12, 12))\n",
    "columns = 5\n",
    "rows = 1\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(x_train1[img_idx, 8:-8, 8:-8, :])\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(x_train2[img_idx, 8:-8, 8:-8, :])\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(layer_output[img_idx, :, :, 0])\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "plt.imshow(prediction[img_idx, :, :, :])\n",
    "fig.add_subplot(rows, columns, 5)\n",
    "plt.imshow(y_train[img_idx, :, :, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
