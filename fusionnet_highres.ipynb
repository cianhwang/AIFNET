{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "_optimizer = Adam(0.0002, 0.5)\n",
    "#_optimizer = Adam(0.001, 0.9)\n",
    "from keras import losses\n",
    "\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(path, number, train_type):\n",
    "    result=np.empty((number, 256, 256, 3), dtype=\"uint8\")\n",
    "    for i in range(number):\n",
    "        I = cv2.imread(path + \"{:05}_{}.jpeg\".format(i+1, train_type))\n",
    "        if I is None:\n",
    "            print(path + \"{:05}_{}.jpeg\".format(i+1, train_type))\n",
    "        #print(I.shape)\n",
    "        if I.shape == (512,512,3):\n",
    "            I = cv2.resize(I, (0,0), fx=0.5, fy=0.5)\n",
    "        elif I.shape == (258,258,3):\n",
    "            I = I[1:-1, 1:-1, :]\n",
    "        result[i, :, :, :] = I\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(y[0, :, :, :])\n",
    "# plt.show()\n",
    "# print(y.max())\n",
    "# print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(x, _filters, _kernel_size, _strides, bn = True):\n",
    "    y = layers.Conv2D(filters = _filters, kernel_size = _kernel_size, \n",
    "                      strides = _strides, padding=\"same\",\n",
    "                      kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(x)\n",
    "    if bn is True:\n",
    "        y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_net(y):\n",
    "    y = encoder_block(y, 32, (5, 5), (4, 4), bn = False)\n",
    "    y = encoder_block(y, 128, (5, 5), (4, 4))\n",
    "    y = encoder_block(y, 256, (5, 5), (4, 4))\n",
    "    y = encoder_block(y, 256, (5, 5), (4, 4))\n",
    "#    y = encoder_block(y, 256, (5, 5), (2, 2))\n",
    "#   y = encoder_block(y, 256, (5, 5), (4, 4))\n",
    "#    y = encoder_block(y, 256, (5, 5), (2, 2))\n",
    "#    y = encoder_block(y, 256, (5, 5), (4, 4))\n",
    "#    y = encoder_block(y, 256, (5, 5), (2, 2))\n",
    "#     y = layers.Flatten()(y)\n",
    "#     y = layers.Dense(256, \n",
    "#                      kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(y)\n",
    "#     y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "#     y = layers.ReLU()(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(x, _filters, _kernel_size, _strides, dropout = False):\n",
    "    y = layers.Conv2DTranspose(filters = _filters, kernel_size = _kernel_size, \n",
    "                               strides=_strides, padding=\"same\",\n",
    "                               kernel_initializer=keras.initializers.RandomNormal(stddev=0.02))(x)\n",
    "    y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "    if dropout is True:\n",
    "        y = layers.Dropout(0.5)(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_net(y):\n",
    "#     y = layers.Dense(8*8*256, \n",
    "#                      kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(y)\n",
    "\n",
    "#     y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "#     y = layers.ReLU()(y)\n",
    "\n",
    "#     y = layers.Reshape((8, 8, 256))(y)\n",
    "#    y = decoder_block(y, 256, (5, 5), (4, 4))\n",
    "#    y = decoder_block(y, 256, (5, 5), (2, 2))\n",
    "#    y = decoder_block(y, 256, (5, 5), (4, 4))\n",
    "#    y = decoder_block(y, 256, (5, 5), (2, 2))\n",
    "    y = decoder_block(y, 256, (5, 5), (4, 4))\n",
    "#    y = decoder_block(y, 256, (5, 5), (2, 2), False)\n",
    "    y = decoder_block(y, 256, (5, 5), (4, 4), False)\n",
    "    y = decoder_block(y, 128, (5, 5), (4, 4), False)\n",
    "    #print(y._keras_shape)\n",
    "    y = decoder_block(y, 32, (5, 5), (4, 4), False)\n",
    "    \n",
    "    '''BLOCK PROBLEM'''\n",
    "    y = encoder_block(y, 16, (5, 5), (1, 1), bn = False)\n",
    "    y = layers.Conv2D(filters = 1, kernel_size = (5, 5), padding = \"same\",\n",
    "                      activation=\"tanh\",\n",
    "                      kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(y)\n",
    "    #y = layers.Softmax(axis = -1)(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionnet(inTensor1, inTensor2):\n",
    "    out1 = encoder_net(inTensor1)\n",
    "    out2 = encoder_net(inTensor2)\n",
    "    x = layers.Concatenate(axis = -1)([out1, out2])\n",
    "    y = decoder_net(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionnetPos(y):\n",
    "    y, inTensor1, inTensor2 = y\n",
    "#     # crop the input images to the same size as network output.\n",
    "#     inCrop1 = layers.Cropping2D(cropping=((8, 8), (8, 8)))(inTensor1)\n",
    "#     inCrop2 = layers.CroppinimgIdx = 9\n",
    "    y = K.tile(y, [1, 1, 1, 3])\n",
    "    y1 = layers.Multiply()([inTensor1, (1+y)/2])\n",
    "    y2 = layers.Multiply()([inTensor2, 1-(1+y)/2])\n",
    "    y = layers.Add()([y1, y2])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = layers.Input(shape=(256, 256, 3))\n",
    "img2 = layers.Input(shape=(256, 256, 3))\n",
    "intermed = fusionnet(img1, img2) # intermed: mask layer\n",
    "\n",
    "pred = layers.Lambda(fusionnetPos)([intermed, img1, img2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''2 outputs: 'pred' for GAN loss and 'intermed' for mask loss'''\n",
    "generator = Model(inputs = [img1, img2], outputs = [pred, intermed])\n",
    "#generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''load images, parse test/validation set'''\n",
    "\n",
    "dataNum_arr = [2000, 1500, 1500]\n",
    "dataPath_arr = [\"highres_dataset2/\", \"Sign_gen/\", \"highres_bbset/\"]\n",
    "x1 = np.empty((0, 256, 256, 3), 'uint8')\n",
    "x2 = np.empty((0, 256, 256, 3), 'uint8')\n",
    "y = np.empty((0, 256, 256, 3), 'uint8')\n",
    "\n",
    "for i in range(len(dataPath_arr)):\n",
    "    x1 = np.append(x1, load_imgs(dataPath_arr[i], dataNum_arr[i], 1), axis = 0)\n",
    "    x2 = np.append(x2, load_imgs(dataPath_arr[i], dataNum_arr[i], 2), axis = 0)\n",
    "    y = np.append(y, load_imgs(dataPath_arr[i], dataNum_arr[i], 0), axis = 0)\n",
    "\n",
    "x_train1, x_test1, x_train2, x_test2, y_train, y_test = train_test_split(\n",
    "    x1, x2, y, test_size=0.2, random_state=7412)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv_loss(y_true, y_pred):\n",
    "    mapping = tf.square(y_pred+1)*tf.square(y_pred-1)/(tf.square(y_pred)+1)\n",
    "    loss = tf.reduce_mean(mapping)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(features, labels, batch_size):\n",
    "    features1, features2 = features\n",
    " # Create empty arrays to contain batch of features and labels#\n",
    "    batch_features1 = np.zeros((batch_size, 256, 256, 3))\n",
    "    batch_features2 = np.zeros((batch_size, 256, 256, 3))\n",
    "    batch_labels = np.zeros((batch_size, 256, 256, 3))\n",
    "    while True:\n",
    "        for i in np.arange(0, features1.shape[0] - batch_size, batch_size):\n",
    "            # choose random index in features\n",
    "            batch_features1 = features1[i:i+batch_size, :, :, :].astype('float16')/127.5-1\n",
    "            batch_features2 = features2[i:i+batch_size, :, :, :].astype('float16')/127.5-1\n",
    "            batch_labels= labels[i:i+batch_size, :, :, :].astype('float16')/127.5-1\n",
    "            yield ([batch_features1, batch_features2], [batch_labels, np.zeros(batch_labels.shape)[:, :, :, :1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4000/4000 [==============================] - 56s 14ms/step - loss: 0.0063 - lambda_1_loss: 0.0063 - conv2d_10_loss: 0.5299\n",
      "Epoch 2/50\n",
      "4000/4000 [==============================] - 51s 13ms/step - loss: 0.0042 - lambda_1_loss: 0.0042 - conv2d_10_loss: 0.3748\n",
      "Epoch 3/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0035 - lambda_1_loss: 0.0035 - conv2d_10_loss: 0.3229\n",
      "Epoch 4/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0032 - lambda_1_loss: 0.0032 - conv2d_10_loss: 0.2994\n",
      "Epoch 5/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0029 - lambda_1_loss: 0.0029 - conv2d_10_loss: 0.2751\n",
      "Epoch 6/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0028 - lambda_1_loss: 0.0028 - conv2d_10_loss: 0.2577\n",
      "Epoch 7/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0027 - lambda_1_loss: 0.0027 - conv2d_10_loss: 0.2382\n",
      "Epoch 8/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0027 - lambda_1_loss: 0.0027 - conv2d_10_loss: 0.2337\n",
      "Epoch 9/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0025 - lambda_1_loss: 0.0025 - conv2d_10_loss: 0.2224\n",
      "Epoch 10/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0024 - lambda_1_loss: 0.0024 - conv2d_10_loss: 0.2007\n",
      "Epoch 11/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0024 - lambda_1_loss: 0.0024 - conv2d_10_loss: 0.1886\n",
      "Epoch 12/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0024 - lambda_1_loss: 0.0024 - conv2d_10_loss: 0.1830\n",
      "Epoch 13/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0023 - lambda_1_loss: 0.0023 - conv2d_10_loss: 0.1768\n",
      "Epoch 14/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0022 - lambda_1_loss: 0.0022 - conv2d_10_loss: 0.1609\n",
      "Epoch 15/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0022 - lambda_1_loss: 0.0022 - conv2d_10_loss: 0.1565\n",
      "Epoch 16/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0024 - lambda_1_loss: 0.0024 - conv2d_10_loss: 0.1853\n",
      "Epoch 17/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0021 - lambda_1_loss: 0.0021 - conv2d_10_loss: 0.1646\n",
      "Epoch 18/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0021 - lambda_1_loss: 0.0021 - conv2d_10_loss: 0.1478\n",
      "Epoch 19/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0020 - lambda_1_loss: 0.0020 - conv2d_10_loss: 0.1406\n",
      "Epoch 20/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0020 - lambda_1_loss: 0.0020 - conv2d_10_loss: 0.1365\n",
      "Epoch 21/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0020 - lambda_1_loss: 0.0020 - conv2d_10_loss: 0.1287\n",
      "Epoch 22/50\n",
      "4000/4000 [==============================] - 52s 13ms/step - loss: 0.0020 - lambda_1_loss: 0.0020 - conv2d_10_loss: 0.1263\n",
      "Epoch 23/50\n",
      "2064/4000 [==============>...............] - ETA: 25s - loss: 0.0020 - lambda_1_loss: 0.0020 - conv2d_10_loss: 0.1301"
     ]
    }
   ],
   "source": [
    "'''train on generator using MSE of pred & mask.'''\n",
    "\n",
    "generator.compile(loss=[losses.mean_squared_error, tv_loss], loss_weights=[1, 0], optimizer= _optimizer)\n",
    "batchSize = 16\n",
    "\n",
    "# generator.fit_generator(data_gen([x_train1, x_train2], y_train, batchSize),\n",
    "#                         x1.shape[0]/batchSize, epochs = 300)\n",
    "generator.fit([x_train1.astype('float16')/127.5-1, x_train2.astype('float16')/127.5-1],\n",
    "              [y_train.astype('float16')/127.5-1, np.zeros(y_train.shape)[:,:,:,:1]], \n",
    "              batch_size = batchSize, epochs=50)\n",
    "\n",
    "# for e in range(10000):\n",
    "#     print(\"epoch {}:\".format(e), end = \"\")\n",
    "#     rand_idx = np.random.randint(0, x_train1.shape[0], size = batchSize)\n",
    "#     img_batch1 = x_train1[rand_idx, :, :, :].astype('float16')/127.5-1\n",
    "#     img_batch2 = x_train2[rand_idx, :, :, :].astype('float16')/127.5-1\n",
    "#     mask_batch = mask_train[rand_idx, :, :, :].astype('float16')/127.5-1\n",
    "#     y_batch = y_train[rand_idx, :, :, :].astype('float16')/127.5-1\n",
    "#     loss = generator.train_on_batch([img_batch1, img_batch2], [y_batch, mask_batch])\n",
    "#     print(loss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.save_weights('my_model_0_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, a= generator.predict([x_train1[:25, :, :, :]/127.5-1, x_train2[:25, :, :, :]/127.5-1])\n",
    "get_layer_output = K.function([generator.layers[0].input, generator.layers[1].input],\n",
    "                                  [generator.layers[-2].output])\n",
    "\n",
    "layer_output = np.array(get_layer_output([x_train1[:25, :, :, :]/127.5-1, x_train2[:25, :, :, :]/127.5-1])[0])\n",
    "#print(prediction.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgIdx in range(10,20):\n",
    "    fig=plt.figure(figsize=(12, 12))\n",
    "    columns = 5\n",
    "    rows = 1\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    plt.imshow(x_train1[imgIdx, :, :, :])\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    plt.imshow(x_train2[imgIdx, :, :, :])\n",
    "    fig.add_subplot(rows, columns, 3)\n",
    "    plt.imshow((layer_output[imgIdx, :, :, 0]+1)/2)\n",
    "    fig.add_subplot(rows, columns, 4)\n",
    "    plt.imshow((prediction[imgIdx, :, :, :]+1)/2)\n",
    "    fig.add_subplot(rows, columns, 5)\n",
    "    plt.imshow(y_train[imgIdx, :, :, :])\n",
    "    plt.show()    \n",
    "# fig.savefig(dataPath+\"results/struc_loss{:.2E}.png\".format(lambda_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, a= generator.predict([x_test1[:25, :, :, :]/127.5-1, x_test2[:25, :, :, :]/127.5-1])\n",
    "get_layer_output = K.function([generator.layers[0].input, generator.layers[1].input],\n",
    "                                  [generator.layers[-2].output])\n",
    "\n",
    "layer_output = np.array(get_layer_output([x_test1[:25, :, :, :]/127.5-1, x_test2[:25, :, :, :]/127.5-1])[0])\n",
    "#print(prediction.max())\n",
    "for imgIdx in range(10,20):\n",
    "    fig=plt.figure(figsize=(12, 12))\n",
    "    columns = 5\n",
    "    rows = 1\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    plt.imshow(x_test1[imgIdx, :, :, :])\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    plt.imshow(x_test2[imgIdx, :, :, :])\n",
    "    fig.add_subplot(rows, columns, 3)\n",
    "    plt.imshow((layer_output[imgIdx, :, :, 0]+1)/2)\n",
    "    fig.add_subplot(rows, columns, 4)\n",
    "    plt.imshow((prediction[imgIdx, :, :, :]+1)/2)\n",
    "    fig.add_subplot(rows, columns, 5)\n",
    "    plt.imshow(y_test[imgIdx, :, :, :])\n",
    "    plt.show()    \n",
    "# fig.savefig(dataPath+\"results/struc_loss{:.2E}.png\".format(lambda_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.save_weights('my_model_weights.h5')\n",
    "\n",
    "# # # from keras.models import load_model\n",
    "# # # model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
