{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.measure import compare_ssim as SSIM\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "_optimizer = Adam(0.0002, 0.5)\n",
    "from keras import losses\n",
    "\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(path, number, train_type):\n",
    "    result=np.empty((number, 64, 64, 3), dtype=\"float64\")\n",
    "    for i in range(number):\n",
    "        I = cv2.imread(path + \"{:05}_{}.jpeg\".format(i+1, train_type))\n",
    "        result[i, :, :, :] = I[4:-4, 4:-4, :]\n",
    "    return result/result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load images, parse test/validation set'''\n",
    "\n",
    "dataNum = 4000\n",
    "dataPath = \"testcase_mass/\"\n",
    "x1 = load_imgs(dataPath, dataNum, 1)\n",
    "x2 = load_imgs(dataPath, dataNum, 2)\n",
    "y = load_imgs(\"testcase_mass/\", dataNum, 0)\n",
    "#y = y[:, 8:-8, 8:-8, :]\n",
    "mask1 = load_imgs(dataPath, dataNum, 4)\n",
    "#mask1 = mask1[:, 8:-8, 8:-8, :1]\n",
    "mask1 = mask1[:, :, :, :1]\n",
    "mask2 = 1-mask1\n",
    "mask = np.concatenate((mask1, mask2), axis = 3)\n",
    "\n",
    "x_train1, x_test1, x_train2, x_test2, y_train, y_test, mask_train, mask_test = train_test_split(\n",
    "    x1, x2, y, mask, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(x, _filters, _kernel_size, _strides):\n",
    "    y = layers.Conv2D(filters = _filters, kernel_size = _kernel_size, \n",
    "                      strides = _strides, padding=\"same\",\n",
    "                      kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(x)\n",
    "    y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_net(y):\n",
    "    y = encoder_block(y, 64, (5, 5), (2, 2))\n",
    "    y = encoder_block(y, 128, (5, 5), (2, 2))\n",
    "    y = encoder_block(y, 256, (5, 5), (2, 2))\n",
    "#     y = layers.Flatten()(y)\n",
    "#     y = layers.Dense(256, \n",
    "#                      kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(y)\n",
    "#     y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "#     y = layers.ReLU()(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(x, _filters, _kernel_size, _strides):\n",
    "    y = layers.Conv2DTranspose(filters = _filters, kernel_size = _kernel_size, \n",
    "                               strides=_strides, padding=\"same\",\n",
    "                               kernel_initializer=keras.initializers.RandomNormal(stddev=0.02))(x)\n",
    "    y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_net(y):\n",
    "#     y = layers.Dense(8*8*256, \n",
    "#                      kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(y)\n",
    "\n",
    "#     y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "#     y = layers.ReLU()(y)\n",
    "#     y = layers.Reshape((8, 8, 256))(y)\n",
    "    y = decoder_block(y, 256, (5, 5), (2, 2))\n",
    "    y = decoder_block(y, 128, (5, 5), (2, 2))\n",
    "    #print(y._keras_shape)\n",
    "    y = decoder_block(y, 32, (5, 5), (2, 2))\n",
    "    y = layers.Conv2D(filters = 2, kernel_size = (5, 5), padding = \"same\",\n",
    "                      activation=\"tanh\",\n",
    "                      kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(y)\n",
    "    y = layers.Softmax(axis = -1)(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionnet(inTensor1, inTensor2):\n",
    "    out1 = encoder_net(inTensor1)\n",
    "    out2 = encoder_net(inTensor2)\n",
    "    x = layers.Concatenate(axis = -1)([out1, out2])\n",
    "    y = decoder_net(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionnetPos(y):\n",
    "    y, inTensor1, inTensor2 = y\n",
    "#     # crop the input images to the same size as network output.\n",
    "#     inCrop1 = layers.Cropping2D(cropping=((8, 8), (8, 8)))(inTensor1)\n",
    "#     inCrop2 = layers.Cropping2D(cropping=((8, 8), (8, 8)))(inTensor2)\n",
    "    y1 = y[:, :, :, :1]\n",
    "    y2 = y[:, :, :, 1:]\n",
    "    y1 = K.tile(y1, [1, 1, 1, 3])\n",
    "    y2 = K.tile(y2, [1, 1, 1, 3])\n",
    "    y1 = layers.Multiply()([inTensor1, y1])\n",
    "    y2 = layers.Multiply()([inTensor2, y2])\n",
    "    y = layers.Add()([y1, y2])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = layers.Input(shape=(64, 64, 3))\n",
    "img2 = layers.Input(shape=(64, 64, 3))\n",
    "intermed = fusionnet(img1, img2) # intermed: mask layer\n",
    "\n",
    "pred = layers.Lambda(fusionnetPos)([intermed, img1, img2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   4864        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   4864        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 128)  204928      re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 128)  204928      re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 16, 16, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 16, 16, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 256)    819456      re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 256)    819456      re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 256)    1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 256)    1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 8, 8, 256)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 8, 8, 256)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 512)    0           re_lu_3[0][0]                    \n",
      "                                                                 re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 256)  3277056     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 256)  1024        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 16, 16, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 128)  819328      re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 32, 32, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 32)   102432      re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 32)   128         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 64, 64, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 2)    1602        re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, 64, 64, 2)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 64, 64, 3)    0           softmax_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,264,162\n",
      "Trainable params: 6,261,538\n",
      "Non-trainable params: 2,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''2 outputs: 'pred' for GAN loss and 'intermed' for mask loss'''\n",
    "generator = Model(inputs = [img1, img2], outputs = [pred, intermed])\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''train on generator using MSE of pred & mask.'''\n",
    "\n",
    "# lambda_tv = 0\n",
    "# generator.compile(loss=[losses.mean_squared_error, tv_loss], loss_weights=[1, lambda_tv], optimizer= _optimizer)\n",
    "# generator.fit([x_train1, x_train2], [y_train, mask_train], batch_size=64, epochs=20)\n",
    "\n",
    "# prediction, a = generator.predict([x_test1[:100, :, :, :], x_test2[:100, :, :, :]])\n",
    "# get_layer_output = K.function([generator.layers[0].input, generator.layers[1].input],\n",
    "#                                   [generator.layers[-2].output])\n",
    "\n",
    "# layer_output = np.array(get_layer_output([x_test1[:100, :, :, :], x_test2[:100, :, :, :]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgIdx = 11\n",
    "# fig=plt.figure(figsize=(12, 12))\n",
    "# columns = 6\n",
    "# rows = 1\n",
    "# fig.add_subplot(rows, columns, 1)\n",
    "# plt.imshow(x_test1[imgIdx, :, :, :])\n",
    "# fig.add_subplot(rows, columns, 2)\n",
    "# plt.imshow(x_test2[imgIdx, :, :, :])\n",
    "# fig.add_subplot(rows, columns, 3)\n",
    "# plt.imshow(mask_test[imgIdx, :, :, 0])\n",
    "# fig.add_subplot(rows, columns, 4)\n",
    "# plt.imshow(layer_output[imgIdx, :, :, 0])\n",
    "# fig.add_subplot(rows, columns, 5)\n",
    "# plt.imshow(prediction[imgIdx, :, :, :])\n",
    "# fig.add_subplot(rows, columns, 6)\n",
    "# plt.imshow(y_test[imgIdx, :, :, :])\n",
    "# plt.show()\n",
    "\n",
    "# #fig.savefig(dataPath+\"results/{}.png\".format(lambda_mse))\n",
    "\n",
    "# ssimList = []\n",
    "# for imgIdx in range(1, 100):\n",
    "#     ssim = SSIM(y_test[imgIdx, :, :, :], prediction[imgIdx, :, :, :], data_range=1, multichannel=True)\n",
    "#     ssimList.append(ssim)\n",
    "#     #print(ssim)\n",
    "# plt.hist(ssimList, bins = 20)\n",
    "# ssimArr = np.array(ssimList)\n",
    "# print(ssimArr.mean())\n",
    "# print(ssimArr.std())\n",
    "# #plt.savefig(dataPath+\"results/{}_{:.3f}_{:.3f}.png\".format(lambda_mse, ssimArr.mean(), ssimArr.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(losses[\"d\"], label='discriminitive loss')\n",
    "    plt.plot(losses[\"g\"], label='generative loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = generator.predict([x_test1[:100, :, :, :], x_test2[:100, :, :, :]])\n",
    "get_layer_output = K.function([generator.layers[0].input, generator.layers[1].input],\n",
    "                                  [generator.layers[-2].output])\n",
    "\n",
    "layer_output = np.array(get_layer_output([x_test1[:100, :, :, :], x_test2[:100, :, :, :]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('x_test1.npy', x_test1)\n",
    "# np.save('x_test2.npy', x_test2)\n",
    "# np.save('y_test.npy', y_test)\n",
    "# np.save('prediction.npy', prediction[0])\n",
    "# np.save('layer_output.npy', layer_output)\n",
    "# np.save('mask_test.npy', mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ssimList = []\n",
    "# # ssimList1 = []\n",
    "# # ssimList2 = []\n",
    "# # ada = 999\n",
    "# for imgIdx in range(1, 100):\n",
    "# #     ssim = SSIM(y_test[imgIdx, :, :, :], prediction[0][imgIdx, :, :, :], data_range=1, multichannel=True)\n",
    "# #     ssimList.append(ssim)\n",
    "# #     ssim1 = SSIM(y_test[imgIdx, :, :, :], x_test1[imgIdx, 8:-8, 8:-8, :], data_range=1, multichannel=True)\n",
    "# #     ssimList1.append(ssim)\n",
    "# #     ssim2 = SSIM(y_test[imgIdx, :, :, :], x_test2[imgIdx, 8:-8, 8:-8, :], data_range=1, multichannel=True)\n",
    "# #     ssimList2.append(ssim)\n",
    "# #     print(ssim1)\n",
    "# #     print(ssim2)\n",
    "# #     print(ssim)\n",
    "# #    imgIdx = 312\n",
    "#     fig=plt.figure(figsize=(12, 12))\n",
    "#     columns = 6\n",
    "#     rows = 1\n",
    "#     fig.add_subplot(rows, columns, 1)\n",
    "#     plt.imshow(x_test1[imgIdx, 8:-8, 8:-8, :])\n",
    "#     fig.add_subplot(rows, columns, 2)\n",
    "#     plt.imshow(x_test2[imgIdx, 8:-8, 8:-8, :])\n",
    "#     fig.add_subplot(rows, columns, 3)\n",
    "#     plt.imshow(mask_test[imgIdx, :, :, 0])\n",
    "#     fig.add_subplot(rows, columns, 4)\n",
    "#     plt.imshow(prediction[0][imgIdx, :, :, :])\n",
    "#     fig.add_subplot(rows, columns, 5)\n",
    "#     plt.imshow(y_test[imgIdx, :, :, :])\n",
    "#     fig.add_subplot(rows, columns, 6)\n",
    "#     plt.imshow(layer_output[imgIdx, :, :, 0])\n",
    "#     plt.show()\n",
    "#     fig.savefig(dataPath+\"results/{}.png\".format(imgIdx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(ssimList, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.save('generator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
