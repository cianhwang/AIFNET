{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "#from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(y, nb_channels, _strides = (1,1), _project_shortcut=False):\n",
    "    shortcut = y\n",
    "\n",
    "    y = layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
    "    #y = layers.BatchNormalization()(y)\n",
    "    y = layers.ReLU()(y)\n",
    "\n",
    "    y = layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=(1, 1), padding='same')(y)\n",
    "    #y = layers.BatchNormalization()()\n",
    "\n",
    "    if _project_shortcut or _strides != (1, 1):\n",
    "        shortcut = layers.Conv2D(nb_channels, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    y = layers.add([shortcut, y])\n",
    "    #y = layers.LeakyReLU()(y)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_net(x, nb_channels, _strides=(1, 1)):\n",
    "    x = layers.Conv2D(64, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(x)\n",
    "    shortcut = x\n",
    "    for _ in range(16):\n",
    "        x = res_block(x, 64)\n",
    "\n",
    "    x = layers.Conv2D(64, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(x)\n",
    "    x = layers.add([shortcut, x])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, nb_channels, _strides=(1, 1)):\n",
    "    x = layers.Conv2D(32, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(x)\n",
    "    #x = layers.Conv2D(64, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_net(y, nb_channels, _strides=(1, 1)):\n",
    "    #y = layers.Conv2D(64, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(y)\n",
    "    #y = layers.Conv2D(32, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(y)\n",
    "    y = layers.Conv2D(3, kernel_size=(3, 3), strides=_strides, padding='same', activation='linear')(y)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_imgs(path, number, train_type):\n",
    "    result=np.empty((number, 64, 64, 3), dtype=\"float64\")\n",
    "    for i in range(number):\n",
    "        I = cv2.imread(path + \"{:04}_{}.jpeg\".format(i+1, train_type))\n",
    "        result[i, :, :, :] = I\n",
    "    return result/result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inport training data\n",
    "dataNum = 1000\n",
    "x1_train = load_imgs(\"./blurImg/\", dataNum, 1)\n",
    "x2_train = load_imgs(\"./blurImg/\", dataNum, 2)\n",
    "y_train = load_imgs(\"./blurImg/\", dataNum, 0)\n",
    "\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "        \n",
    "def loss_wrapper(in_tensor1, in_tensor2):\n",
    "    def gaussian_blur(in_tensor):\n",
    "        # use large kernel to blur pred and in_tensor//\n",
    "        return\n",
    "        \n",
    "    def custom_loss(y_true, y_pred):\n",
    "        # or better implementation like fourier transformation\n",
    "        return K.binary_crossentropy(y_true, y_pred) + K.reduce_mean(K.square(gaussian_blur(y_pred)-gaussian_blur(in_tensor1)))\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_829 (Conv2D)             (None, 64, 64, 64)   1792        input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_863 (Conv2D)             (None, 64, 64, 64)   1792        input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_830 (Conv2D)             (None, 64, 64, 64)   36928       conv2d_829[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_864 (Conv2D)             (None, 64, 64, 64)   36928       conv2d_863[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_385 (ReLU)                (None, 64, 64, 64)   0           conv2d_830[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_401 (ReLU)                (None, 64, 64, 64)   0           conv2d_864[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_831 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_385[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_865 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_401[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_409 (Add)                   (None, 64, 64, 64)   0           conv2d_829[0][0]                 \n",
      "                                                                 conv2d_831[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_426 (Add)                   (None, 64, 64, 64)   0           conv2d_863[0][0]                 \n",
      "                                                                 conv2d_865[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_832 (Conv2D)             (None, 64, 64, 64)   36928       add_409[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_866 (Conv2D)             (None, 64, 64, 64)   36928       add_426[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_386 (ReLU)                (None, 64, 64, 64)   0           conv2d_832[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_402 (ReLU)                (None, 64, 64, 64)   0           conv2d_866[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_833 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_386[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_867 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_402[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_410 (Add)                   (None, 64, 64, 64)   0           add_409[0][0]                    \n",
      "                                                                 conv2d_833[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_427 (Add)                   (None, 64, 64, 64)   0           add_426[0][0]                    \n",
      "                                                                 conv2d_867[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_834 (Conv2D)             (None, 64, 64, 64)   36928       add_410[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_868 (Conv2D)             (None, 64, 64, 64)   36928       add_427[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_387 (ReLU)                (None, 64, 64, 64)   0           conv2d_834[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_403 (ReLU)                (None, 64, 64, 64)   0           conv2d_868[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_835 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_387[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_869 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_403[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_411 (Add)                   (None, 64, 64, 64)   0           add_410[0][0]                    \n",
      "                                                                 conv2d_835[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_428 (Add)                   (None, 64, 64, 64)   0           add_427[0][0]                    \n",
      "                                                                 conv2d_869[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_836 (Conv2D)             (None, 64, 64, 64)   36928       add_411[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_870 (Conv2D)             (None, 64, 64, 64)   36928       add_428[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_388 (ReLU)                (None, 64, 64, 64)   0           conv2d_836[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_404 (ReLU)                (None, 64, 64, 64)   0           conv2d_870[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_837 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_388[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_871 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_404[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_412 (Add)                   (None, 64, 64, 64)   0           add_411[0][0]                    \n",
      "                                                                 conv2d_837[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_429 (Add)                   (None, 64, 64, 64)   0           add_428[0][0]                    \n",
      "                                                                 conv2d_871[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_838 (Conv2D)             (None, 64, 64, 64)   36928       add_412[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_872 (Conv2D)             (None, 64, 64, 64)   36928       add_429[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_389 (ReLU)                (None, 64, 64, 64)   0           conv2d_838[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_405 (ReLU)                (None, 64, 64, 64)   0           conv2d_872[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_839 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_389[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_873 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_405[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_413 (Add)                   (None, 64, 64, 64)   0           add_412[0][0]                    \n",
      "                                                                 conv2d_839[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_430 (Add)                   (None, 64, 64, 64)   0           add_429[0][0]                    \n",
      "                                                                 conv2d_873[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_840 (Conv2D)             (None, 64, 64, 64)   36928       add_413[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_874 (Conv2D)             (None, 64, 64, 64)   36928       add_430[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_390 (ReLU)                (None, 64, 64, 64)   0           conv2d_840[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_406 (ReLU)                (None, 64, 64, 64)   0           conv2d_874[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_841 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_390[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_875 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_406[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_414 (Add)                   (None, 64, 64, 64)   0           add_413[0][0]                    \n",
      "                                                                 conv2d_841[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_431 (Add)                   (None, 64, 64, 64)   0           add_430[0][0]                    \n",
      "                                                                 conv2d_875[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_842 (Conv2D)             (None, 64, 64, 64)   36928       add_414[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_876 (Conv2D)             (None, 64, 64, 64)   36928       add_431[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_391 (ReLU)                (None, 64, 64, 64)   0           conv2d_842[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_407 (ReLU)                (None, 64, 64, 64)   0           conv2d_876[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_843 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_391[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_877 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_407[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_415 (Add)                   (None, 64, 64, 64)   0           add_414[0][0]                    \n",
      "                                                                 conv2d_843[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_432 (Add)                   (None, 64, 64, 64)   0           add_431[0][0]                    \n",
      "                                                                 conv2d_877[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_844 (Conv2D)             (None, 64, 64, 64)   36928       add_415[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_878 (Conv2D)             (None, 64, 64, 64)   36928       add_432[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_392 (ReLU)                (None, 64, 64, 64)   0           conv2d_844[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_408 (ReLU)                (None, 64, 64, 64)   0           conv2d_878[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_845 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_392[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_879 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_408[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_416 (Add)                   (None, 64, 64, 64)   0           add_415[0][0]                    \n",
      "                                                                 conv2d_845[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_433 (Add)                   (None, 64, 64, 64)   0           add_432[0][0]                    \n",
      "                                                                 conv2d_879[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_846 (Conv2D)             (None, 64, 64, 64)   36928       add_416[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_880 (Conv2D)             (None, 64, 64, 64)   36928       add_433[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_393 (ReLU)                (None, 64, 64, 64)   0           conv2d_846[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_409 (ReLU)                (None, 64, 64, 64)   0           conv2d_880[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_847 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_393[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_881 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_409[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_417 (Add)                   (None, 64, 64, 64)   0           add_416[0][0]                    \n",
      "                                                                 conv2d_847[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_434 (Add)                   (None, 64, 64, 64)   0           add_433[0][0]                    \n",
      "                                                                 conv2d_881[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_848 (Conv2D)             (None, 64, 64, 64)   36928       add_417[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_882 (Conv2D)             (None, 64, 64, 64)   36928       add_434[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_394 (ReLU)                (None, 64, 64, 64)   0           conv2d_848[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_410 (ReLU)                (None, 64, 64, 64)   0           conv2d_882[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_849 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_394[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_883 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_410[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_418 (Add)                   (None, 64, 64, 64)   0           add_417[0][0]                    \n",
      "                                                                 conv2d_849[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_435 (Add)                   (None, 64, 64, 64)   0           add_434[0][0]                    \n",
      "                                                                 conv2d_883[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_850 (Conv2D)             (None, 64, 64, 64)   36928       add_418[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_884 (Conv2D)             (None, 64, 64, 64)   36928       add_435[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_395 (ReLU)                (None, 64, 64, 64)   0           conv2d_850[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_411 (ReLU)                (None, 64, 64, 64)   0           conv2d_884[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_851 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_395[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_885 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_411[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_419 (Add)                   (None, 64, 64, 64)   0           add_418[0][0]                    \n",
      "                                                                 conv2d_851[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_436 (Add)                   (None, 64, 64, 64)   0           add_435[0][0]                    \n",
      "                                                                 conv2d_885[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_852 (Conv2D)             (None, 64, 64, 64)   36928       add_419[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_886 (Conv2D)             (None, 64, 64, 64)   36928       add_436[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_396 (ReLU)                (None, 64, 64, 64)   0           conv2d_852[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_412 (ReLU)                (None, 64, 64, 64)   0           conv2d_886[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_853 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_396[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_887 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_412[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_420 (Add)                   (None, 64, 64, 64)   0           add_419[0][0]                    \n",
      "                                                                 conv2d_853[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_437 (Add)                   (None, 64, 64, 64)   0           add_436[0][0]                    \n",
      "                                                                 conv2d_887[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_854 (Conv2D)             (None, 64, 64, 64)   36928       add_420[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_888 (Conv2D)             (None, 64, 64, 64)   36928       add_437[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_397 (ReLU)                (None, 64, 64, 64)   0           conv2d_854[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_413 (ReLU)                (None, 64, 64, 64)   0           conv2d_888[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_855 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_397[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_889 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_413[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_421 (Add)                   (None, 64, 64, 64)   0           add_420[0][0]                    \n",
      "                                                                 conv2d_855[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_438 (Add)                   (None, 64, 64, 64)   0           add_437[0][0]                    \n",
      "                                                                 conv2d_889[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_856 (Conv2D)             (None, 64, 64, 64)   36928       add_421[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_890 (Conv2D)             (None, 64, 64, 64)   36928       add_438[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_398 (ReLU)                (None, 64, 64, 64)   0           conv2d_856[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_414 (ReLU)                (None, 64, 64, 64)   0           conv2d_890[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_857 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_398[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_891 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_414[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_422 (Add)                   (None, 64, 64, 64)   0           add_421[0][0]                    \n",
      "                                                                 conv2d_857[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_439 (Add)                   (None, 64, 64, 64)   0           add_438[0][0]                    \n",
      "                                                                 conv2d_891[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_858 (Conv2D)             (None, 64, 64, 64)   36928       add_422[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_892 (Conv2D)             (None, 64, 64, 64)   36928       add_439[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_399 (ReLU)                (None, 64, 64, 64)   0           conv2d_858[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_415 (ReLU)                (None, 64, 64, 64)   0           conv2d_892[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_859 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_399[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_893 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_415[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_423 (Add)                   (None, 64, 64, 64)   0           add_422[0][0]                    \n",
      "                                                                 conv2d_859[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_440 (Add)                   (None, 64, 64, 64)   0           add_439[0][0]                    \n",
      "                                                                 conv2d_893[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_860 (Conv2D)             (None, 64, 64, 64)   36928       add_423[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_894 (Conv2D)             (None, 64, 64, 64)   36928       add_440[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_400 (ReLU)                (None, 64, 64, 64)   0           conv2d_860[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_416 (ReLU)                (None, 64, 64, 64)   0           conv2d_894[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_861 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_400[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_895 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_416[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_424 (Add)                   (None, 64, 64, 64)   0           add_423[0][0]                    \n",
      "                                                                 conv2d_861[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_441 (Add)                   (None, 64, 64, 64)   0           add_440[0][0]                    \n",
      "                                                                 conv2d_895[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_862 (Conv2D)             (None, 64, 64, 64)   36928       add_424[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_896 (Conv2D)             (None, 64, 64, 64)   36928       add_441[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_425 (Add)                   (None, 64, 64, 64)   0           conv2d_829[0][0]                 \n",
      "                                                                 conv2d_862[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_442 (Add)                   (None, 64, 64, 64)   0           conv2d_863[0][0]                 \n",
      "                                                                 conv2d_896[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64, 64, 128)  0           add_425[0][0]                    \n",
      "                                                                 add_442[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_897 (Conv2D)             (None, 64, 64, 3)    3459        concatenate_13[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 2,444,291\n",
      "Trainable params: 2,444,291\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qian/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "img_a = layers.Input(shape=(64, 64, 3))\n",
    "img_b = layers.Input(shape=(64, 64, 3))\n",
    "#feature_a = conv_net(img_a, 3)\n",
    "#feature_b = conv_net(img_b, 3)\n",
    "feature_a = res_net(img_a, 3)\n",
    "feature_b = res_net(img_b, 3)\n",
    "merge = layers.concatenate([feature_a, feature_b])\n",
    "aif = post_net(merge, 128)\n",
    "gen = Model(inputs = [img_a, img_b], output = [aif])\n",
    "#gen.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#gen.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "gen.summary()\n",
    "#plot_model(gen, to_file='generator.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"a.jpg\", 255.0*(gen_img[4]-gen_img[4].min())/(gen_img[4].max()-gen_img[4].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_898 (Conv2D)          (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_899 (Conv2D)          (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_900 (Conv2D)          (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_901 (Conv2D)          (None, 64, 64, 1)         2305      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,471,298\n",
      "Trainable params: 2,471,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_fake = gen([img_a, img_b])\n",
    "dis = Sequential()\n",
    "dis.add(layers.Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "dis.add(layers.LeakyReLU())\n",
    "dis.add(layers.Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "dis.add(layers.LeakyReLU())\n",
    "dis.add(layers.Conv2D(256, kernel_size=(3, 3), padding='same'))\n",
    "dis.add(layers.LeakyReLU())\n",
    "dis.add(layers.Conv2D(1, kernel_size=(3, 3), padding='same'))\n",
    "\n",
    "dis.add(layers.Flatten())\n",
    "dis.add(layers.Dense(512, activation='tanh'))\n",
    "dis.add(layers.Dense(1))\n",
    "dis.add(layers.Activation('sigmoid'))\n",
    "pred_prob = dis(image_fake)\n",
    "dis.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "dis.summary()\n",
    "plot_model(dis, to_file='discriminator.png')\n",
    "make_trainable(dis, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qian/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_13 (Model)                (None, 64, 64, 3)    2444291     input_25[0][0]                   \n",
      "                                                                 input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 1)            2471298     model_13[1][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,915,589\n",
      "Trainable params: 2,444,291\n",
      "Non-trainable params: 2,471,298\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "am = Model(inputs = [img_a, img_b], output = [pred_prob])\n",
    "am.summary()\n",
    "am.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "plot_model(am, to_file='adversary.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-train discriminate network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        plt.figure(figsize=(10,8))\n",
    "        plt.plot(losses[\"d\"], label='discriminitive loss')\n",
    "        plt.plot(losses[\"g\"], label='generative loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: model_13/conv2d_883/convolution = Conv2D[T=DT_FLOAT, _class=[\"loc:@train...kpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model_13/re_lu_410/Relu, conv2d_883/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_12/mul/_14309 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7380_loss_12/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-9640bb4cc47e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# train Generator-Discriminator stack on input noise to non-generated output class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmake_trainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_batch1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_batch1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#same batch or ???\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"g\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m25\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m25\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: model_13/conv2d_883/convolution = Conv2D[T=DT_FLOAT, _class=[\"loc:@train...kpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model_13/re_lu_410/Relu, conv2d_883/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_12/mul/_14309 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7380_loss_12/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "# Train discriminator on generated images\n",
    "losses = {\"d\":[], \"g\":[]}\n",
    "Batch_size = 64\n",
    "nb_epoch = 100\n",
    "for epoch in range(nb_epoch):\n",
    "    rand_idx = np.random.randint(0, x1_train.shape[0], size = Batch_size)\n",
    "    img_batch1 = x1_train[rand_idx, :, :, :]\n",
    "    img_batch2 = x2_train[rand_idx, :, :, :]\n",
    "    y_batch = y_train[np.random.randint(0, y_train.shape[0], size = Batch_size), :, :, :]\n",
    "    #gen.fit([x1_train, x2_train], y_train)\n",
    "    gen_img = gen.predict([img_batch1, img_batch2])\n",
    "    X = np.concatenate((y_batch, gen_img))\n",
    "    y = np.zeros([2*Batch_size,])\n",
    "    y[0:Batch_size] = 1\n",
    "    y[Batch_size:] = 0\n",
    "    make_trainable(dis,True)\n",
    "    d_loss = dis.train_on_batch(X, y)\n",
    "    losses[\"d\"].append(d_loss)\n",
    "    \n",
    "    y2 = np.ones([Batch_size, ])\n",
    "    # train Generator-Discriminator stack on input noise to non-generated output class\n",
    "    make_trainable(dis,False)\n",
    "    g_loss = am.train_on_batch([img_batch1, img_batch1], y2) #same batch or ???\n",
    "    losses[\"g\"].append(g_loss)\n",
    "    if epoch % 25 == 25 - 1:\n",
    "        plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "64/64 [==============================] - 8s 119ms/step - loss: 1201.6720 - acc: 0.3019\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.3614 - acc: 0.3938\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 24.9446 - acc: 0.2841\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 134.7787 - acc: 0.2597\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 6.3969 - acc: 0.5315\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 2.7259 - acc: 0.4355\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 6.2487 - acc: 0.3875\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 1.0824 - acc: 0.3719\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.6969 - acc: 0.1989\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.3318 - acc: 0.3700\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2714 - acc: 0.4335\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.2054 - acc: 0.2958\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1776 - acc: 0.2533\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.1549 - acc: 0.4457\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.1326 - acc: 0.4386\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0980 - acc: 0.2802\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0977 - acc: 0.2266\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0682 - acc: 0.5037\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0822 - acc: 0.5363\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0533 - acc: 0.5173\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0462 - acc: 0.3406\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0522 - acc: 0.2723\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0372 - acc: 0.4375\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0360 - acc: 0.5396\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0360 - acc: 0.5076\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0307 - acc: 0.4951\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0266 - acc: 0.4798\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0271 - acc: 0.3694\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0234 - acc: 0.4355\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0221 - acc: 0.5502\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0213 - acc: 0.5793\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0220 - acc: 0.6193\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0219 - acc: 0.5677\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0221 - acc: 0.5327\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0194 - acc: 0.5192\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0187 - acc: 0.4896\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0198 - acc: 0.5189\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0167 - acc: 0.5959\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0184 - acc: 0.6114\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0166 - acc: 0.5878\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0172 - acc: 0.5647\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0181 - acc: 0.5637\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0185 - acc: 0.4934\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0173 - acc: 0.5949\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0138 - acc: 0.5922\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0183 - acc: 0.5954\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0152 - acc: 0.5734\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0154 - acc: 0.6048\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0165 - acc: 0.6413\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0143 - acc: 0.6343\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0154 - acc: 0.5877\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0145 - acc: 0.6366\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0114 - acc: 0.6414\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0143 - acc: 0.6060\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0115 - acc: 0.6347\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0131 - acc: 0.6378\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0135 - acc: 0.6039\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0130 - acc: 0.6608\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0128 - acc: 0.6184\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0131 - acc: 0.6306\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0110 - acc: 0.6461\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0138 - acc: 0.5901\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0110 - acc: 0.6466\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0111 - acc: 0.6777\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0113 - acc: 0.6105\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0096 - acc: 0.6334\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0097 - acc: 0.6568\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0097 - acc: 0.6781\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0089 - acc: 0.6422\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0098 - acc: 0.6637\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0098 - acc: 0.6659\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0092 - acc: 0.6493\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0091 - acc: 0.6461\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0082 - acc: 0.6447\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0102 - acc: 0.6895\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0089 - acc: 0.6773\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0082 - acc: 0.6558\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0096 - acc: 0.6602\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0109 - acc: 0.5844\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0089 - acc: 0.6745\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0091 - acc: 0.6950\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0095 - acc: 0.6555\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0087 - acc: 0.6904\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0090 - acc: 0.6557\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0080 - acc: 0.6689\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0085 - acc: 0.6547\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0081 - acc: 0.6466\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0086 - acc: 0.6767\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0081 - acc: 0.6707\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0076 - acc: 0.6237\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0096 - acc: 0.6728\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0099 - acc: 0.6385\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0088 - acc: 0.6533\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0077 - acc: 0.6380\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0086 - acc: 0.5878\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0082 - acc: 0.6333\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0077 - acc: 0.6834\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0082 - acc: 0.6822\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0083 - acc: 0.6498\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 0.0073 - acc: 0.6765\n"
     ]
    }
   ],
   "source": [
    "Batch_size = 64\n",
    "nb_epoch = 100\n",
    "for epoch in range(nb_epoch):\n",
    "    rand_idx = np.random.randint(0, x1_train.shape[0], size = Batch_size)\n",
    "    img_batch1 = x1_train[rand_idx, :, :, :]\n",
    "    img_batch2 = x2_train[rand_idx, :, :, :]\n",
    "    y_batch = y_train[rand_idx, :, :, :]\n",
    "    gen.fit([img_batch1, img_batch2], y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-c966d794682b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#gen_img[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#gen_img.min()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgen_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#gen_img[0]\n",
    "#gen_img.min()\n",
    "gen_img = gen.predict([x1_train, x2_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
