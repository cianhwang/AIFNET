{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "#from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(y, nb_channels, _strides = (1,1), _project_shortcut=False):\n",
    "    shortcut = y\n",
    "\n",
    "    y = layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
    "    #y = layers.BatchNormalization()(y)\n",
    "    y = layers.ReLU()(y)\n",
    "\n",
    "    y = layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=(1, 1), padding='same')(y)\n",
    "    #y = layers.BatchNormalization()()\n",
    "\n",
    "    if _project_shortcut or _strides != (1, 1):\n",
    "        shortcut = layers.Conv2D(nb_channels, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    y = layers.add([shortcut, y])\n",
    "    #y = layers.LeakyReLU()(y)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_net(x, nb_channels, _strides=(1, 1)):\n",
    "    x = layers.Conv2D(64, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(x)\n",
    "    shortcut = x\n",
    "    for _ in range(16):\n",
    "        x = res_block(x, 64)\n",
    "\n",
    "    x = layers.Conv2D(64, kernel_size=(3, 3), strides=_strides, padding='same', activation='sigmoid')(x)\n",
    "    x = layers.add([shortcut, x])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, nb_channels, _strides=(1, 1)):\n",
    "    x = layers.Conv2D(32, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(x)\n",
    "    #x = layers.Conv2D(64, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_net(y, nb_channels, _strides=(1, 1)):\n",
    "    #y = layers.Conv2D(64, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(y)\n",
    "    #y = layers.Conv2D(32, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(y)\n",
    "    y = layers.Conv2D(3, kernel_size=(3, 3), strides=_strides, padding='same', activation='tanh')(y)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_imgs(path, number, train_type):\n",
    "    result=np.empty((number, 64, 64, 3), dtype=\"float64\")\n",
    "    for i in range(number):\n",
    "        I = cv2.imread(path + \"{:04}_{}.jpeg\".format(i+1, train_type))\n",
    "        result[i, :, :, :] = I\n",
    "    return result/result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inport training data\n",
    "dataNum = 1000\n",
    "x1_train = load_imgs(\"./blurImg/\", dataNum, 1)\n",
    "x2_train = load_imgs(\"./blurImg/\", dataNum, 2)\n",
    "y_train = load_imgs(\"./blurImg/\", dataNum, 0)\n",
    "\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "        \n",
    "def loss_wrapper(in_tensor1, in_tensor2):\n",
    "    def gaussian_blur(in_tensor):\n",
    "        # use large kernel to blur pred and in_tensor//\n",
    "        return\n",
    "        \n",
    "    def custom_loss(y_true, y_pred):\n",
    "        # or better implementation like fourier transformation\n",
    "        return K.binary_crossentropy(y_true, y_pred) + K.reduce_mean(K.square(gaussian_blur(y_pred)-gaussian_blur(in_tensor1)))\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 64, 64, 64)   1792        input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_411 (Conv2D)             (None, 64, 64, 64)   1792        input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 64, 64, 64)   36928       conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_412 (Conv2D)             (None, 64, 64, 64)   36928       conv2d_411[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_161 (ReLU)                (None, 64, 64, 64)   0           conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_177 (ReLU)                (None, 64, 64, 64)   0           conv2d_412[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_161[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_413 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_177[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_171 (Add)                   (None, 64, 64, 64)   0           conv2d_377[0][0]                 \n",
      "                                                                 conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_188 (Add)                   (None, 64, 64, 64)   0           conv2d_411[0][0]                 \n",
      "                                                                 conv2d_413[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 64, 64, 64)   36928       add_171[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_414 (Conv2D)             (None, 64, 64, 64)   36928       add_188[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_162 (ReLU)                (None, 64, 64, 64)   0           conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_178 (ReLU)                (None, 64, 64, 64)   0           conv2d_414[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_162[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_415 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_178[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_172 (Add)                   (None, 64, 64, 64)   0           add_171[0][0]                    \n",
      "                                                                 conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_189 (Add)                   (None, 64, 64, 64)   0           add_188[0][0]                    \n",
      "                                                                 conv2d_415[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, 64, 64, 64)   36928       add_172[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_416 (Conv2D)             (None, 64, 64, 64)   36928       add_189[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_163 (ReLU)                (None, 64, 64, 64)   0           conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_179 (ReLU)                (None, 64, 64, 64)   0           conv2d_416[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_163[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_417 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_179[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_173 (Add)                   (None, 64, 64, 64)   0           add_172[0][0]                    \n",
      "                                                                 conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_190 (Add)                   (None, 64, 64, 64)   0           add_189[0][0]                    \n",
      "                                                                 conv2d_417[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, 64, 64, 64)   36928       add_173[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_418 (Conv2D)             (None, 64, 64, 64)   36928       add_190[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_164 (ReLU)                (None, 64, 64, 64)   0           conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_180 (ReLU)                (None, 64, 64, 64)   0           conv2d_418[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_164[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_419 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_180[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_174 (Add)                   (None, 64, 64, 64)   0           add_173[0][0]                    \n",
      "                                                                 conv2d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_191 (Add)                   (None, 64, 64, 64)   0           add_190[0][0]                    \n",
      "                                                                 conv2d_419[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_386 (Conv2D)             (None, 64, 64, 64)   36928       add_174[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_420 (Conv2D)             (None, 64, 64, 64)   36928       add_191[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_165 (ReLU)                (None, 64, 64, 64)   0           conv2d_386[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_181 (ReLU)                (None, 64, 64, 64)   0           conv2d_420[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_387 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_165[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_421 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_181[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_175 (Add)                   (None, 64, 64, 64)   0           add_174[0][0]                    \n",
      "                                                                 conv2d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_192 (Add)                   (None, 64, 64, 64)   0           add_191[0][0]                    \n",
      "                                                                 conv2d_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_388 (Conv2D)             (None, 64, 64, 64)   36928       add_175[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_422 (Conv2D)             (None, 64, 64, 64)   36928       add_192[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_166 (ReLU)                (None, 64, 64, 64)   0           conv2d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_182 (ReLU)                (None, 64, 64, 64)   0           conv2d_422[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_389 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_166[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_423 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_182[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_176 (Add)                   (None, 64, 64, 64)   0           add_175[0][0]                    \n",
      "                                                                 conv2d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_193 (Add)                   (None, 64, 64, 64)   0           add_192[0][0]                    \n",
      "                                                                 conv2d_423[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_390 (Conv2D)             (None, 64, 64, 64)   36928       add_176[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_424 (Conv2D)             (None, 64, 64, 64)   36928       add_193[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_167 (ReLU)                (None, 64, 64, 64)   0           conv2d_390[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_183 (ReLU)                (None, 64, 64, 64)   0           conv2d_424[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_391 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_167[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_425 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_183[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_177 (Add)                   (None, 64, 64, 64)   0           add_176[0][0]                    \n",
      "                                                                 conv2d_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_194 (Add)                   (None, 64, 64, 64)   0           add_193[0][0]                    \n",
      "                                                                 conv2d_425[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_392 (Conv2D)             (None, 64, 64, 64)   36928       add_177[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_426 (Conv2D)             (None, 64, 64, 64)   36928       add_194[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_168 (ReLU)                (None, 64, 64, 64)   0           conv2d_392[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_184 (ReLU)                (None, 64, 64, 64)   0           conv2d_426[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_393 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_168[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_427 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_184[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_178 (Add)                   (None, 64, 64, 64)   0           add_177[0][0]                    \n",
      "                                                                 conv2d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_195 (Add)                   (None, 64, 64, 64)   0           add_194[0][0]                    \n",
      "                                                                 conv2d_427[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_394 (Conv2D)             (None, 64, 64, 64)   36928       add_178[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_428 (Conv2D)             (None, 64, 64, 64)   36928       add_195[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_169 (ReLU)                (None, 64, 64, 64)   0           conv2d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_185 (ReLU)                (None, 64, 64, 64)   0           conv2d_428[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_395 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_169[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_429 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_185[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_179 (Add)                   (None, 64, 64, 64)   0           add_178[0][0]                    \n",
      "                                                                 conv2d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_196 (Add)                   (None, 64, 64, 64)   0           add_195[0][0]                    \n",
      "                                                                 conv2d_429[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_396 (Conv2D)             (None, 64, 64, 64)   36928       add_179[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_430 (Conv2D)             (None, 64, 64, 64)   36928       add_196[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_170 (ReLU)                (None, 64, 64, 64)   0           conv2d_396[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_186 (ReLU)                (None, 64, 64, 64)   0           conv2d_430[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_397 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_170[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_431 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_186[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_180 (Add)                   (None, 64, 64, 64)   0           add_179[0][0]                    \n",
      "                                                                 conv2d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_197 (Add)                   (None, 64, 64, 64)   0           add_196[0][0]                    \n",
      "                                                                 conv2d_431[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_398 (Conv2D)             (None, 64, 64, 64)   36928       add_180[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_432 (Conv2D)             (None, 64, 64, 64)   36928       add_197[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_171 (ReLU)                (None, 64, 64, 64)   0           conv2d_398[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_187 (ReLU)                (None, 64, 64, 64)   0           conv2d_432[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_399 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_171[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_433 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_187[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_181 (Add)                   (None, 64, 64, 64)   0           add_180[0][0]                    \n",
      "                                                                 conv2d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_198 (Add)                   (None, 64, 64, 64)   0           add_197[0][0]                    \n",
      "                                                                 conv2d_433[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_400 (Conv2D)             (None, 64, 64, 64)   36928       add_181[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_434 (Conv2D)             (None, 64, 64, 64)   36928       add_198[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_172 (ReLU)                (None, 64, 64, 64)   0           conv2d_400[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_188 (ReLU)                (None, 64, 64, 64)   0           conv2d_434[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_401 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_172[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_435 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_188[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_182 (Add)                   (None, 64, 64, 64)   0           add_181[0][0]                    \n",
      "                                                                 conv2d_401[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_199 (Add)                   (None, 64, 64, 64)   0           add_198[0][0]                    \n",
      "                                                                 conv2d_435[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_402 (Conv2D)             (None, 64, 64, 64)   36928       add_182[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_436 (Conv2D)             (None, 64, 64, 64)   36928       add_199[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_173 (ReLU)                (None, 64, 64, 64)   0           conv2d_402[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_189 (ReLU)                (None, 64, 64, 64)   0           conv2d_436[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_403 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_173[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_437 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_189[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_183 (Add)                   (None, 64, 64, 64)   0           add_182[0][0]                    \n",
      "                                                                 conv2d_403[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_200 (Add)                   (None, 64, 64, 64)   0           add_199[0][0]                    \n",
      "                                                                 conv2d_437[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_404 (Conv2D)             (None, 64, 64, 64)   36928       add_183[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_438 (Conv2D)             (None, 64, 64, 64)   36928       add_200[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_174 (ReLU)                (None, 64, 64, 64)   0           conv2d_404[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_190 (ReLU)                (None, 64, 64, 64)   0           conv2d_438[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_405 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_174[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_439 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_190[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_184 (Add)                   (None, 64, 64, 64)   0           add_183[0][0]                    \n",
      "                                                                 conv2d_405[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_201 (Add)                   (None, 64, 64, 64)   0           add_200[0][0]                    \n",
      "                                                                 conv2d_439[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_406 (Conv2D)             (None, 64, 64, 64)   36928       add_184[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_440 (Conv2D)             (None, 64, 64, 64)   36928       add_201[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_175 (ReLU)                (None, 64, 64, 64)   0           conv2d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_191 (ReLU)                (None, 64, 64, 64)   0           conv2d_440[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_407 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_175[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_441 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_191[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_185 (Add)                   (None, 64, 64, 64)   0           add_184[0][0]                    \n",
      "                                                                 conv2d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_202 (Add)                   (None, 64, 64, 64)   0           add_201[0][0]                    \n",
      "                                                                 conv2d_441[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_408 (Conv2D)             (None, 64, 64, 64)   36928       add_185[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_442 (Conv2D)             (None, 64, 64, 64)   36928       add_202[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_176 (ReLU)                (None, 64, 64, 64)   0           conv2d_408[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_192 (ReLU)                (None, 64, 64, 64)   0           conv2d_442[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_409 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_176[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_443 (Conv2D)             (None, 64, 64, 64)   36928       re_lu_192[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_186 (Add)                   (None, 64, 64, 64)   0           add_185[0][0]                    \n",
      "                                                                 conv2d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_203 (Add)                   (None, 64, 64, 64)   0           add_202[0][0]                    \n",
      "                                                                 conv2d_443[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_410 (Conv2D)             (None, 64, 64, 64)   36928       add_186[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_444 (Conv2D)             (None, 64, 64, 64)   36928       add_203[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_187 (Add)                   (None, 64, 64, 64)   0           conv2d_377[0][0]                 \n",
      "                                                                 conv2d_410[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_204 (Add)                   (None, 64, 64, 64)   0           conv2d_411[0][0]                 \n",
      "                                                                 conv2d_444[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 128)  0           add_187[0][0]                    \n",
      "                                                                 add_204[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_445 (Conv2D)             (None, 64, 64, 3)    3459        concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,444,291\n",
      "Trainable params: 2,444,291\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qian/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "img_a = layers.Input(shape=(64, 64, 3))\n",
    "img_b = layers.Input(shape=(64, 64, 3))\n",
    "#feature_a = conv_net(img_a, 3)\n",
    "#feature_b = conv_net(img_b, 3)\n",
    "feature_a = res_net(img_a, 3)\n",
    "feature_b = res_net(img_b, 3)\n",
    "merge = layers.concatenate([feature_a, feature_b])\n",
    "aif = post_net(merge, 128)\n",
    "gen = Model(inputs = [img_a, img_b], output = [aif])\n",
    "gen.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#gen.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "gen.summary()\n",
    "#plot_model(gen, to_file='generator.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_446 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_447 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_448 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 4,565,890\n",
      "Trainable params: 4,565,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_fake = gen([img_a, img_b])\n",
    "dis = Sequential()\n",
    "dis.add(layers.Conv2D(64, kernel_size=(3, 3),strides=(2, 2), padding='same'))\n",
    "dis.add(layers.LeakyReLU())\n",
    "#dis.add(layers.Dropout(0.25))\n",
    "dis.add(layers.Conv2D(128, kernel_size=(3, 3), strides=(2, 2),padding='same'))\n",
    "dis.add(layers.LeakyReLU())\n",
    "#dis.add(layers.Dropout(0.25))\n",
    "dis.add(layers.Conv2D(256, kernel_size=(3, 3), strides=(2, 2),padding='same'))\n",
    "dis.add(layers.LeakyReLU())\n",
    "#dis.add(layers.Dropout(0.25))\n",
    "#dis.add(layers.Conv2D(1, kernel_size=(3, 3), padding='same'))\n",
    "\n",
    "dis.add(layers.Flatten())\n",
    "dis.add(layers.Dense(256))\n",
    "dis.add(layers.Dense(2))\n",
    "dis.add(layers.Activation('softmax'))\n",
    "pred_prob = dis(image_fake)\n",
    "dis.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "dis.summary()\n",
    "#plot_model(dis, to_file='discriminator.png')\n",
    "make_trainable(dis, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: GPU sync failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-7ddb33478979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m#losses[\"d\"].append(d_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 199\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "#pre-train discriminate network\n",
    "make_trainable(dis,True)\n",
    "Batch_size = 64\n",
    "nb_epoch = 100\n",
    "for epoch in range(nb_epoch):\n",
    "    rand_idx = np.random.randint(0, x1_train.shape[0], size = Batch_size)\n",
    "    img_batch1 = x1_train[rand_idx, :, :, :]\n",
    "    img_batch2 = x2_train[rand_idx, :, :, :]\n",
    "    y_batch = y_train[np.random.randint(0, y_train.shape[0], size = Batch_size), :, :, :]\n",
    "    X = np.concatenate((y_batch, img_batch1))\n",
    "    y = np.zeros([2*Batch_size,2])\n",
    "    y[0:Batch_size, 0] = 1\n",
    "    y[Batch_size:, 1] = 1\n",
    "\n",
    "    dis.fit(X, y)\n",
    "    #losses[\"d\"].append(d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 64, 64, 3)    2444291     input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 2)            2471811     model_3[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,916,102\n",
      "Trainable params: 2,444,291\n",
      "Non-trainable params: 2,471,811\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qian/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "am = Model(inputs = [img_a, img_b], output = [pred_prob])\n",
    "am.summary()\n",
    "am.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#plot_model(am, to_file='adversary.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        plt.figure(figsize=(10,8))\n",
    "        plt.plot(losses[\"d\"], label='discriminitive loss')\n",
    "        plt.plot(losses[\"g\"], label='generative loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6948 - acc: 0.6250\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 5s 80ms/step - loss: 0.3957 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6768 - acc: 0.5703\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7078 - acc: 0.4375\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.3744 - acc: 0.7656\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 3.2414 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0239 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 6.6027 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 2.8408 - acc: 0.7109\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 1.1341e-04 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 4.3456 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 3.0009 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.0231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 1.4322 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.2239 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.8069 - acc: 0.4375\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.7987 - acc: 0.0312\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.8182 - acc: 0.4922\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 1.7433 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.8998 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 1.2105 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7137 - acc: 0.5078\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.3152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.8682 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.2168 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.8868 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.4560 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7400 - acc: 0.4453\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.9696 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7323 - acc: 0.4922\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.9138 - acc: 0.0156\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7275 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.3594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7697 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.4493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.7227 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6384 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7090 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.9298 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7093 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.7675 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.6974 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.6266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7018 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.5735 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7061 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.5969 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6970 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.7383 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6933 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.6702 - acc: 0.2812\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7174 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.5253 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7234 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.4880 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7262 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.4572 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7017 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.2507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.8884 - acc: 0.3594\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.1911 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.9958 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.2244 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.8158 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.7173 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7308 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 1.2419 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7812 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 1.0368 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7182 - acc: 0.4219\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.5566 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7274 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.4368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7274 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6472 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6914 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.8248 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7049 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.8426 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7063 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6452 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6960 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.6299 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6952 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.6662 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.6931 - acc: 0.4922\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7361 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6957 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.7119 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6951 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7270 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6938 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.0469\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6927 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6542 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6940 - acc: 0.5078\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6906 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6942 - acc: 0.4375\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6950 - acc: 0.4375\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7054 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6941 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6925 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6966 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6568 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6969 - acc: 0.4375\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7239 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6953 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7013 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6969 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7197 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6943 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.6558 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6941 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.6604 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7043 - acc: 0.4219\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.7626 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6941 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.6977 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6945 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.6327 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6969 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6950 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6974 - acc: 0.4297\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.7436 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6961 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6955 - acc: 0.5078\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6668 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6941 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6945 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7495 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6966 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.7495 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6988 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.6270 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7026 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7045 - acc: 0.4219\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7882 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6995 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.7729 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6929 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6726 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6935 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.6476 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6948 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6471 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6937 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6942 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6956 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7515 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6957 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6814 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6943 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6866 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6968 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.6543 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.6995 - acc: 0.4219\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.7376 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6984 - acc: 0.4375\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.6600 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6996 - acc: 0.4062\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.7364 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6957 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.6687 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6939 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7015 - acc: 0.4531\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7532 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6965 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6430 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6963 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.6777 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6980 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.6628 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.6943 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.6937 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6944 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7452 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6967 - acc: 0.4531\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.6788 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6937 - acc: 0.4844\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6982 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6945 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6738 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.7135 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6952 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7029 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.7046 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.7418 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6937 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.6255 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train discriminator on generated images\n",
    "losses = {\"d\":[], \"g\":[]}\n",
    "Batch_size = 64\n",
    "nb_epoch = 100\n",
    "for epoch in range(nb_epoch):\n",
    "    rand_idx = np.random.randint(0, x1_train.shape[0], size = Batch_size)\n",
    "    img_batch1 = x1_train[rand_idx, :, :, :]\n",
    "    img_batch2 = x2_train[rand_idx, :, :, :]\n",
    "    y_batch = y_train[np.random.randint(0, y_train.shape[0], size = Batch_size), :, :, :]\n",
    "    #gen.fit([x1_train, x2_train], y_train)\n",
    "    gen_img = gen.predict([img_batch1, img_batch2])\n",
    "    X = np.concatenate((y_batch, gen_img))\n",
    "    y = np.zeros([2*Batch_size,])\n",
    "    y[0:Batch_size] = 1\n",
    "    y[Batch_size:] = 0\n",
    "    make_trainable(dis,True)\n",
    "    dis.fit(X, y)\n",
    "    #losses[\"d\"].append(d_loss)\n",
    "    \n",
    "    y2 = np.ones([Batch_size, ])\n",
    "    # train Generator-Discriminator stack on input noise to non-generated output class\n",
    "    make_trainable(dis,False)\n",
    "    am.fit([img_batch1, img_batch1], y2) #same batch or ???\n",
    "    #losses[\"g\"].append(g_loss)\n",
    "    #if epoch % 25 == 25 - 1:\n",
    "    #    plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "64/64 [==============================] - 5s 76ms/step - loss: 8.7845 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.3324 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.2125 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 32ms/step - loss: 8.9807 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.3150 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.9990 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.1182 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.3191 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 8.5524 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 9.0752 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.0041 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7823 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.3836 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.3748 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7283 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.1307 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 9.2824 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.9747 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7682 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7839 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7911 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7477 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7506 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.3278 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 9.0284 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 8.8481 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.9186 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 8.7319 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 8.8998 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.4566 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 32ms/step - loss: 8.9270 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 9.0898 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.8679 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 32ms/step - loss: 9.2662 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.9228 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.8340 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7811 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7522 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.5692 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.9712 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.9113 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.0077 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.0466 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.4695 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.6763 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.6450 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 9.0800 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 8.3643 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 9.4129 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.1201 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.9136 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 9.2870 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.1156 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.4370 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 32ms/step - loss: 8.9783 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 8.6714 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 8.8733 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 32ms/step - loss: 8.9406 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.3479 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 8.8359 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7566 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 8.6188 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.8652 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.8118 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.8774 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 9.0741 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7530 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.0208 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.1870 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 32ms/step - loss: 9.3401 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.8800 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.9460 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.5025 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7967 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.5013 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.9485 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.6507 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.2024 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.0223 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.0676 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.4433 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.3314 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.3055 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.6882 - acc: 0.0000e+00\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 33ms/step - loss: 8.9552 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.9202 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.4503 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 8.4251 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.2337 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7880 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.4816 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.4385 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.7507 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.8783 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 9.3385 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 8.8217 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.4746 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.8620 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.1317 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 8.6635 - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "Batch_size = 64\n",
    "nb_epoch = 100\n",
    "for epoch in range(nb_epoch):\n",
    "    rand_idx = np.random.randint(0, x1_train.shape[0], size = Batch_size)\n",
    "    img_batch1 = x1_train[rand_idx, :, :, :]\n",
    "    img_batch2 = x2_train[rand_idx, :, :, :]\n",
    "    y_batch = y_train[rand_idx, :, :, :]\n",
    "    gen.fit([img_batch1, img_batch2], y_batch)\n",
    "    \n",
    "\n",
    "#gen_img[0]\n",
    "#gen_img.min()\n",
    "#gen_img = gen.predict([x1_train, x2_train])    \n",
    "#cv2.imwrite(\"a.jpg\", 255.0*(gen_img[4]-gen_img[4].min())/(gen_img[4].max()-gen_img[4].min()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
