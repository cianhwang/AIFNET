{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.measure import compare_ssim as SSIM\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "_optimizer = Adam(0.0002, 0.5)\n",
    "from keras import losses\n",
    "\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(path, number, train_type):\n",
    "    result=np.empty((number, 72, 72, 3), dtype=\"float64\")\n",
    "    for i in range(number):\n",
    "        I = cv2.imread(path + \"{:05}_{}.jpeg\".format(i+1, train_type))\n",
    "        result[i, :, :, :] = I\n",
    "    return result/result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load images, parse test/validation set'''\n",
    "dataNum = 4000\n",
    "dataPath = \"testcase_mass/\"\n",
    "x1 = load_imgs(dataPath, dataNum, 1)\n",
    "x2 = load_imgs(dataPath, dataNum, 2)\n",
    "y = load_imgs(dataPath, dataNum, 0)\n",
    "y = y[:, 8:-8, 8:-8, :]\n",
    "mask1 = load_imgs(dataPath, dataNum, 4)\n",
    "mask1 = mask1[:, 8:-8, 8:-8, :1]\n",
    "mask2 = 1-mask1\n",
    "mask = np.concatenate((mask1, mask2), axis = 3)\n",
    "\n",
    "x_train1, x_test1, x_train2, x_test2, y_train, y_test, mask_train, mask_test = train_test_split(\n",
    "    x1, x2, y, mask, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input size: Nonex48x48x3\n",
    "# output size: Nonex36x36x16\n",
    "def pre_convblock(x):\n",
    "    y = layers.Conv2D(filters = 16, kernel_size = (5, 5), padding = \"valid\", \n",
    "                     kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(x)\n",
    "    y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(filters = 32, kernel_size = (5, 5), padding = \"valid\", \n",
    "                     kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(y)\n",
    "    y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(filters = 16, kernel_size = (5, 5), padding = \"valid\", \n",
    "                     kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(y)\n",
    "    y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor format: [batch, in_height, in_width, in_channels]\n",
    "# input size: Nonex36x36x32 (cat: 16+16)\n",
    "# output size: Nonex32x32x2\n",
    "# softmax is applied along the channel axis.\n",
    "def post_convblock(x):\n",
    "    y = layers.Conv2D(filters = 64, kernel_size=(3, 3), padding = \"valid\",\n",
    "                     kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(x)\n",
    "    y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(filters = 32, kernel_size=(1, 1), padding = \"valid\",\n",
    "                     kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(y)\n",
    "    y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(filters = 2, kernel_size=(3, 3), padding = \"valid\", activation = 'tanh',\n",
    "                     kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(y)\n",
    "\n",
    "    y = layers.Softmax(axis = -1)(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: out-of-focus image block A & block B, which denote the same area of the whole picture.\n",
    "#        each: 48x48x3\n",
    "# output: \n",
    "def fusionnet(inTensor1, inTensor2):\n",
    "    out1 = pre_convblock(inTensor1)\n",
    "    out2 = pre_convblock(inTensor2)\n",
    "\n",
    "    x = layers.Concatenate(axis = -1)([out1, out2])\n",
    "    y = post_convblock(x)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionnetPos(y):\n",
    "    y, inTensor1, inTensor2 = y\n",
    "    # crop the input images to the same size as network output.\n",
    "    inCrop1 = layers.Cropping2D(cropping=((8, 8), (8, 8)))(inTensor1)\n",
    "    inCrop2 = layers.Cropping2D(cropping=((8, 8), (8, 8)))(inTensor2)\n",
    "    y1 = y[:, :, :, :1]\n",
    "    y2 = y[:, :, :, 1:]\n",
    "    y1 = K.tile(y1, [1, 1, 1, 3])     # extend y1&y2 dimension to 3, consistant to color channels\n",
    "    y2 = K.tile(y2, [1, 1, 1, 3])\n",
    "    y1 = layers.Multiply()([inCrop1, y1])\n",
    "    y2 = layers.Multiply()([inCrop2, y2])\n",
    "    y = layers.Add()([y1, y2])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = layers.Input(shape=(72, 72, 3))\n",
    "img2 = layers.Input(shape=(72, 72, 3))\n",
    "intermed = fusionnet(img1, img2) # intermed: mask layer\n",
    "pred = layers.Lambda(fusionnetPos)([intermed, img1, img2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 72, 72, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 72, 72, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 68, 68, 16)   1216        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 68, 68, 16)   1216        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 68, 68, 16)   64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 68, 68, 16)   64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 68, 68, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 68, 68, 16)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 32)   12832       re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 32)   12832       re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 32)   128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 64, 64, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 64, 64, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 60, 60, 16)   12816       re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 60, 60, 16)   12816       re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 60, 60, 16)   64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 60, 60, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 60, 60, 16)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 60, 60, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 60, 60, 32)   0           re_lu_11[0][0]                   \n",
      "                                                                 re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 58, 58, 64)   18496       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 58, 58, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 58, 58, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 58, 58, 32)   2080        re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 58, 58, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 58, 58, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 56, 56, 2)    578         re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "softmax_2 (Softmax)             (None, 56, 56, 2)    0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 56, 56, 3)    0           softmax_2[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 75,778\n",
      "Trainable params: 75,330\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''2 outputs: 'pred' for GAN loss and 'intermed' for mask loss'''\n",
    "generator = Model(inputs = [img1, img2], outputs = [pred, intermed])\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''tv_loss: designed constraint on mask. WORKS NOT WELL.'''\n",
    "\n",
    "def tv_loss(y_true, y_pred):\n",
    "    #mapping = tf.cast(y_pred > 0.5, y_pred.dtype)\n",
    "    #loss = tf.reduce_mean(tf.image.total_variation(mapping))\n",
    "\n",
    "#     mapping = 0.25 - tf.square(y_pred-0.5) # 0.25-(x-0.5)^2\n",
    "#     sigma = 0.2\n",
    "#     mu = 0.5\n",
    "#     mapping = tf.exp(-0.5*tf.square((y_pred - mu)/sigma))\n",
    "    mapping = tf.square(y_pred)*tf.square(y_pred-1)/(tf.square(y_pred-0.5)+0.25)\n",
    "    loss = tf.reduce_mean(mapping)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''train on generator using MSE of pred & mask.'''\n",
    "\n",
    "# lambda_tv = 1\n",
    "# generator.compile(loss=[losses.mean_squared_error, tv_loss], loss_weights=[1, 0.001], optimizer= _optimizer)\n",
    "# generator.fit([x_train1, x_train2], [y_train, mask_train], batch_size=64, epochs=5)\n",
    "\n",
    "\n",
    "\n",
    "# prediction, a = generator.predict([x1, x2])\n",
    "# get_layer_output = K.function([generator.layers[0].input, generator.layers[1].input],\n",
    "#                                   [generator.layers[-2].output])\n",
    "\n",
    "# layer_output = np.array(get_layer_output([x1, x2])[0])\n",
    "\n",
    "# imgIdx = 6\n",
    "# fig=plt.figure(figsize=(12, 12))\n",
    "# columns = 6\n",
    "# rows = 1\n",
    "# fig.add_subplot(rows, columns, 1)\n",
    "# plt.imshow(x1[imgIdx, 8:-8, 8:-8, :])\n",
    "# fig.add_subplot(rows, columns, 2)\n",
    "# plt.imshow(x2[imgIdx, 8:-8, 8:-8, :])\n",
    "# fig.add_subplot(rows, columns, 3)\n",
    "# plt.imshow(mask[imgIdx, :, :, 0])\n",
    "# fig.add_subplot(rows, columns, 4)\n",
    "# plt.imshow(layer_output[imgIdx, :, :, 0])\n",
    "# fig.add_subplot(rows, columns, 5)\n",
    "# plt.imshow(prediction[imgIdx, :, :, :])\n",
    "# fig.add_subplot(rows, columns, 6)\n",
    "# plt.imshow(y[imgIdx, :, :, :])\n",
    "# plt.show()\n",
    "# # fig.savefig(dataPath+\"results/struc_loss{:.2E}.png\".format(lambda_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_block(x, _filters, _strides, bn = True):\n",
    "    y = layers.Conv2D(filters = _filters, kernel_size = (5, 5), strides = _strides, padding='same',\n",
    "                     kernel_initializer = keras.initializers.RandomNormal(stddev=0.02))(x)\n",
    "    if bn:\n",
    "        y = layers.BatchNormalization(momentum = 0.9, epsilon=1e-5)(y)\n",
    "        \n",
    "    y = layers.LeakyReLU(alpha=0.2)(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disnet(x):\n",
    "    y = dis_block(x, 32, (2, 2), bn = False)\n",
    "    y = dis_block(y, 64, (1, 1))\n",
    "    y = dis_block(y, 64, (2, 2))\n",
    "    y = dis_block(y, 128, (1, 1))\n",
    "    y = dis_block(y, 128, (2, 2))\n",
    "#     y = dis_block(y, 256, (2, 2))\n",
    "#     y = dis_block(y, 256, (2, 2))\n",
    "    y = layers.Flatten()(y)\n",
    "    y = layers.Dense(1, activation='sigmoid')(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 56, 56, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 14, 14, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 14, 14, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 7, 7, 128)         409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 778,625\n",
      "Trainable params: 777,857\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dis_input = layers.Input(shape=(56, 56, 3))\n",
    "dis_output = disnet(dis_input)\n",
    "discriminator = Model(inputs = dis_input, outputs = dis_output)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator.compile(loss='mse', optimizer= _optimizer)\n",
    "# y_fake = generator.predict([x_train1, x_train2])\n",
    "# dis_input = np.concatenate((y_fake, y_train), axis = 0)\n",
    "# label = np.append(np.zeros((y_fake.shape[0], )), np.ones((y_train.shape[0], )))\n",
    "\n",
    "# for e in range(20):\n",
    "#     discriminator.fit(dis_input, label)\n",
    "\n",
    "# label = discriminator.predict(x_test1[:, 8:-8, 8:-8, :])\n",
    "# print(np.sum(label < 0.5))\n",
    "# print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gannet(x):\n",
    "    img1, img2 = x\n",
    "    pred, intermed = generator([img1, img2])\n",
    "    prob = discriminator(pred)\n",
    "    discriminator.trainable = False\n",
    "    return (prob, intermed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 72, 72, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 72, 72, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 [(None, 56, 56, 3),  75778       input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 1)            778625      model_2[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 854,403\n",
      "Trainable params: 75,330\n",
      "Non-trainable params: 779,073\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prob, intermed = gannet([img1, img2])\n",
    "gan = Model(inputs = [img1, img2], outputs= [prob, intermed])\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = gan.predict([x1, x2])\n",
    "# mask = prediction[1]\n",
    "# plt.imshow(mask[6, :, :, 0])\n",
    "# mask_tensor = tf.convert_to_tensor(mask)\n",
    "# tv = tf.image.total_variation(mask_tensor)\n",
    "# sess = tf.Session()\n",
    "# loss = tv.eval(session=sess)\n",
    "\n",
    "# print(loss[:10]/32/32/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(losses[\"d\"], label='discriminitive loss')\n",
    "    plt.plot(losses[\"g\"], label='generative loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_10/convolution}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_10/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_10/kernel/read)]]\n\t [[{{node lambda_2/add_3/add/_539}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_405_lambda_2/add_3/add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4e2bb072fee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmask_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mimg_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_batch1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_batch2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mimg_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdis_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_10/convolution}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_10/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_10/kernel/read)]]\n\t [[{{node lambda_2/add_3/add/_539}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_405_lambda_2/add_3/add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "batchSize = 64\n",
    "losses = {\"d\":[], \"g\":[]}\n",
    "for e in tqdm(range(epoch)):\n",
    "    rand_idx = np.random.randint(0, x_train1.shape[0], size = batchSize)\n",
    "    img_batch1 = x_train1[rand_idx, :, :, :]\n",
    "    img_batch2 = x_train2[rand_idx, :, :, :]\n",
    "    mask_batch = mask_train[rand_idx, :, :, :]\n",
    "    y_batch = y_train[np.random.randint(0, y_train.shape[0], size = batchSize), :, :, :]\n",
    "    img_fake = generator.predict([img_batch1, img_batch2])[0]\n",
    "    img_valid = y_batch\n",
    "    dis_input = np.concatenate((img_fake, img_valid), axis = 0)\n",
    "    label = np.append(np.zeros((batchSize, )), np.ones((batchSize, )))\n",
    "    \n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=_optimizer)\n",
    "    d_loss = discriminator.train_on_batch(dis_input, label)\n",
    "    losses[\"d\"].append(d_loss)\n",
    "    \n",
    "    gan_label = np.ones((batchSize,))\n",
    "    discriminator.trainable = False\n",
    "    gan.compile(loss = ['binary_crossentropy', tv_loss], loss_weights=[1, 0], optimizer=_optimizer)\n",
    "\n",
    "    g_loss = gan.train_on_batch([img_batch1, img_batch2], [gan_label, mask_batch])\n",
    "    losses[\"g\"].append(g_loss[1])\n",
    "    \n",
    "    if e % 5 == 4:\n",
    "        plot_loss(losses)\n",
    "\n",
    "        imgIdx = 16\n",
    "        prediction = generator.predict([x1[imgIdx:imgIdx+1, :, :, :], x2[imgIdx:imgIdx+1, :, :, :]])[0]\n",
    "        #ssim = SSIM(y[imgIdx, :, :, :], prediction[0, :, :, :], data_range=prediction[0, :, :, :].max() - prediction[0, :, :, :].min(), multichannel=True)\n",
    "        #print(ssim)\n",
    "        \n",
    "        get_layer_output = K.function([generator.layers[0].input, generator.layers[1].input],\n",
    "                                          [generator.layers[-2].output])\n",
    "\n",
    "        layer_output = np.array(get_layer_output([x1[imgIdx:imgIdx+1, :, :, :], x2[imgIdx:imgIdx+1, :, :, :]])[0])\n",
    "\n",
    "        fig=plt.figure(figsize=(12, 12))\n",
    "        columns = 6\n",
    "        rows = 1\n",
    "        fig.add_subplot(rows, columns, 1)\n",
    "        plt.imshow(x1[imgIdx, 8:-8, 8:-8, :])\n",
    "        fig.add_subplot(rows, columns, 2)\n",
    "        plt.imshow(x2[imgIdx, 8:-8, 8:-8, :])\n",
    "        fig.add_subplot(rows, columns, 3)\n",
    "        plt.imshow(mask[imgIdx, :, :, 0])\n",
    "        fig.add_subplot(rows, columns, 4)\n",
    "        plt.imshow(layer_output[0, :, :, 0])\n",
    "        fig.add_subplot(rows, columns, 5)\n",
    "        plt.imshow(prediction[0, :, :, :])\n",
    "        fig.add_subplot(rows, columns, 6)\n",
    "        plt.imshow(y[imgIdx, :, :, :])\n",
    "        plt.show()\n",
    "        #fig.savefig(dataPath+\"results/struc_ep{}_{}.png\".format(e,98))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = generator.predict([x_test1, x_test2])\n",
    "# get_layer_output = K.function([generator.layers[0].input, generator.layers[1].input],\n",
    "#                                   [generator.layers[-2].output])\n",
    "\n",
    "# layer_output = np.array(get_layer_output([x_test1, x_test2])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('x_test1.npy', x_test1)\n",
    "# np.save('x_test2.npy', x_test2)\n",
    "# np.save('y_test.npy', y_test)\n",
    "# np.save('prediction.npy', prediction[0])\n",
    "# np.save('layer_output.npy', layer_output)\n",
    "# np.save('mask_test.npy', mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ssimList = []\n",
    "# # ada = 999\n",
    "# for imgIdx in range(1000):\n",
    "# #     ssim = SSIM(y_test[imgIdx, :, :, :], prediction[0][imgIdx, :, :, :], data_range=1, multichannel=True)\n",
    "# #     ssimList.append(ssim)\n",
    "# #     ssim1 = SSIM(y_test[imgIdx, :, :, :], x_test1[imgIdx, 8:-8, 8:-8, :], data_range=1, multichannel=True)\n",
    "# #     ssim2 = SSIM(y_test[imgIdx, :, :, :], x_test2[imgIdx, 8:-8, 8:-8, :], data_range=1, multichannel=True)\n",
    "# #     print(ssim1)\n",
    "# #     print(ssim2)\n",
    "# #     print(ssim)\n",
    "# #    imgIdx = 312\n",
    "#     fig=plt.figure(figsize=(12, 12))\n",
    "#     columns = 6\n",
    "#     rows = 1\n",
    "#     fig.add_subplot(rows, columns, 1)\n",
    "#     plt.imshow(x_test1[imgIdx, 8:-8, 8:-8, :])\n",
    "#     fig.add_subplot(rows, columns, 2)\n",
    "#     plt.imshow(x_test2[imgIdx, 8:-8, 8:-8, :])\n",
    "#     fig.add_subplot(rows, columns, 3)\n",
    "#     plt.imshow(layer_output[imgIdx, :, :, 0])\n",
    "#     fig.add_subplot(rows, columns, 4)\n",
    "#     plt.imshow(prediction[0][imgIdx, :, :, :])\n",
    "#     fig.add_subplot(rows, columns, 5)\n",
    "#     plt.imshow(y_test[imgIdx, :, :, :])\n",
    "#     fig.add_subplot(rows, columns, 6)\n",
    "#     plt.imshow(mask_test[imgIdx, :, :, 0])\n",
    "#     plt.show()\n",
    "#     fig.savefig(dataPath+\"results/{}.png\".format(imgIdx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(ssimList, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.save('generator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
